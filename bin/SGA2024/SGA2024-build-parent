#!/usr/bin/env python

"""Code to build the parent SGA2024 sample based on a combination of internal and external catalogs.

SGA2024-build-parent --in-footprint --mp 128 --overwrite

"""
import pdb # for debugging

import os, time
import numpy as np
import numpy.ma as ma
import fitsio
from astropy.table import Table, vstack, hstack, join

import SGA.io
from SGA.coadds import PIXSCALE, BANDS

basedir = SGA.io.sga_dir()

#from astroquery.ipac.ned import Ned
#qq = Ned.query_object("UM198")
#qq = Ned.get_table('um198', table='diameters')


def domatch_pgc(cat, refcat, rank=0):
    """Match a catalog and a reference catalog based on PGC number and then positionally.

    """
    import astropy.units as u
    from astropy.coordinates import SkyCoord
    from SGA.util import match

    # match on PGC
    if 'PGC' in cat.colnames:
        indx_cat, indx_refcat = match(cat['PGC'], refcat['PGC'])
        print(f'Rank {rank:03d}: Matched {len(indx_cat):,d}/{len(cat):,d} objects based on PGC number.')

        refcols = ['PGC', 'OBJNAME', 'RA', 'DEC', 'LOGD25', 'PA']
        cols = ['PGC', 'GALAXY', 'RA', 'DEC', 'RHALF', 'POSITION_ANGLE', 'ELLIPTICITY', 'SURFACE_BRIGHTNESS_RHALF']
        info = join(refcat[refcols][indx_refcat], cat[cols][indx_cat], keys='PGC',
                    table_names=['REFCAT', 'CAT'])
        print(info[np.argsort(info['SEPARCSEC'])[::-1]])
        
    # match on coordinates
    nopgc = np.where(cat['PGC'] == -1)[0]
    if len(nopgc) > 0:
        print('Rank {rank:03d}: Matching based on coordinates.')
        c_cat = SkyCoord(cat['RA'][nopgc]*u.deg, cat['DEC'][nopgc]*u.deg)
        c_refcat = SkyCoord(refcat['RA']*u.deg, refcat['DEC']*u.deg)
        indx_refcat, sep2d, _ = c_cat.match_to_catalog_sky(c_refcat)
        print(f'Rank {rank:03d}: Mean and max separation between {len(cat)} galaxies is ' \
              '{np.mean(sep2d.arcsec):.3f}+/-{np.std(sep2d.arcsec):.3f}, {np.max(sep2d.arcsec):.3f} arcsec.')

        pdb.set_trace()

        info = hstack((refcat[indx_refcat]['PGC', 'OBJNAME', 'RA', 'DEC', 'LOGD25'], cat['GALAXY', 'RA', 'DEC', 'RHALF', 'SURFACE_BRIGHTNESS_RHALF']))
        info['SEPARCSEC'] = sep2d.arcsec.astype('f4')
    
    pdb.set_trace()


def domatch_coord(cat, refcat, rank=0):
    """Match a catalog and a reference catalog based coordinates.

    """
    import astropy.units as u
    from astropy.coordinates import SkyCoord
    from SGA.util import match

    print('Rank {rank:03d}: Matching based on coordinates.')
    c_cat = SkyCoord(cat['RA']*u.deg, cat['DEC']*u.deg)
    c_refcat = SkyCoord(refcat['RA']*u.deg, refcat['DEC']*u.deg)
    indx_refcat, sep2d, _ = c_cat.match_to_catalog_sky(c_refcat)
    print(f'Rank {rank:03d}: Mean and max separation between {len(cat)} galaxies is ' \
          f'{np.mean(sep2d.arcsec):.3f}+/-{np.std(sep2d.arcsec):.3f}, {np.max(sep2d.arcsec):.3f} arcsec.')

    srt = np.argsort(sep2d)[::-1]
    refcat[indx_refcat[srt]][:10]
    cat[srt][:10]
    
          
    pdb.set_trace()

    info = hstack((refcat[indx_refcat]['PGC', 'OBJNAME', 'RA', 'DEC', 'LOGD25'], cat['GALAXY', 'RA', 'DEC', 'RHALF', 'SURFACE_BRIGHTNESS_RHALF']))
    info['SEPARCSEC'] = sep2d.arcsec.astype('f4')
    
    pdb.set_trace()


def read_cat(catalog):
    """Wrapper to read one of the known external catalogs.

    """
    match catalog.lower():
        case 'hyperleda':
            from SGA.io import read_hyperleda
            cat = read_hyperleda()
        case 'wxsc':
            from SGA.io import read_wxsc
            cat = read_wxsc()
        case 'nedlvs':
            from SGA.io import read_nedlvs
            cat = read_nedlvs()
        case 'lvd':
            from SGA.io import read_lvd
            cat = read_lvd()
        case _:
            raise ValueError(f'Unrecognized catalog name {catalog}')

    return cat


#def _get_ccds(args):
#    """Wrapper for the multiprocessing."""
#    return get_ccds(*args)


def get_ccds(allccds, onegal, width_pixels, pixscale=PIXSCALE, return_ccds=False):
    """Quickly get the CCDs touching this custom brick.  This code is mostly taken
    from legacypipe.runbrick.stage_tims.

    """
    from SGA.coadds import custom_brickname
    from legacypipe.survey import wcs_for_brick, BrickDuck, ccds_touching_wcs

    brickname = f'custom-{custom_brickname(onegal["RA"], onegal["DEC"])}'
    brick = BrickDuck(onegal['RA'], onegal['DEC'], brickname)

    targetwcs = wcs_for_brick(brick, W=float(width_pixels), H=float(width_pixels), pixscale=pixscale)
    I = ccds_touching_wcs(targetwcs, allccds)
    #ccds = survey.ccds_touching_wcs(targetwcs)
    #print(len(I))

    # no CCDs within width_pixels
    if len(I) == 0:
        if return_ccds:
            return Table(), Table()
        else:
            return Table()

    ccds = allccds[I]

    onegal['NCCD'] = len(ccds)
    onegal['FILTERS'] = ''.join(sorted(set(ccds.filter)))
    
    if return_ccds:
        # convert to an astropy Table so we can vstack
        _ccds = ccds.to_dict()
        ccds = Table()
        for key in _ccds.keys():
            ccds[key.upper()] = _ccds[key]

        ccds = ccds['RA', 'DEC', 'CAMERA', 'EXPNUM', 'PLVER', 'CCDNAME', 'FILTER']
        #ccds['GALAXY'] = [galaxy]
        ccds['ROW'] = onegal['ROW']

        return ccds, Table(onegal)
    else:
        return Table(onegal)


def in_footprint(cat, allccds, radius=1., width_pixels=152, bands=BANDS, comm=None, mp=1):
    """Find which objects are in the given survey footprint based on positional
    matching with a very generous (1 deg) search radius.

    radius in degrees

    """
    from astrometry.libkd.spherematch import match_radec
    from SGA.util import weighted_partition, match_to

    if comm is None:
        rank, size = 0, 1
    else:
        rank, size = comm.rank, comm.size

    cat['NCCD'] = np.zeros(len(cat), int)
    cat['FILTERS'] = np.zeros(len(cat), '<U4')

    if rank == 0:
        t0 = time.time()

        # I, which is a list of len(cat), is the variable-length of indices into
        # allccds of the matches, or None if no match (which we filter out).
        indx_ccds = match_radec(cat['RA'], cat['DEC'], allccds.ra, allccds.dec,
                                radius, indexlist=True)

        indx_cat = []
        nccdperobj = []
        for icat, val in enumerate(indx_ccds):
            if val is not None:
                indx_cat.append(icat)
                nccdperobj.append(len(indx_ccds[icat]))
        print(f'Rank {rank:03d}: Found {len(indx_cat):,d}/{len(cat):,d} objects with at least one CCD within {radius} deg.')

        groups = weighted_partition(nccdperobj, size)
    else:
        indx_cat = []
        indx_ccds = []
        groups = [np.array([])]

    # broadcast the work to the other ranks
    if comm:
        indx_cat = comm.bcast(indx_cat, root=0)
        indx_ccds = comm.bcast(indx_ccds, root=0)
        groups = comm.bcast(groups, root=0)

    # now perform a more refined search for each matching object
    
    fcat = []
    #ccds = []
    for icat, indx in enumerate(groups[rank]):
        catindx = indx_cat[indx]
        onegal = cat[catindx]
        if icat % len(groups[rank]) == 0 or icat+1 == len(groups[rank]):
            print(f'Rank {rank:03d}: Working on galaxy: {icat+1:,d}/{len(groups[rank])}')
        #print(f'Rank {rank:03d} working on galaxy: {onegal["GALAXY"]}')
        one_fcat = get_ccds(allccds[indx_ccds[catindx]], onegal, width_pixels,
                            pixscale=PIXSCALE, return_ccds=False)
        fcat.append(one_fcat)

    if len(fcat) > 0:
        fcat = vstack(fcat)
        
    #mpargs = []
    #for icat, catindx in enumerate(M):
    #    mpargs.append([icat, allccds[I[catindx]], cat[catindx], width_pixels, PIXSCALE])
    #
    #if mp > 1:
    #    import multiprocessing
    #    with multiprocessing.Pool(mp) as P:
    #        out = P.map(_get_ccds, mpargs)
    #else:
    #    out = [_get_ccds(_mpargs) for _mpargs in mpargs]
    #out = list(zip(*out))
    #
    #ccds = out[0]
    #fcat = out[1]
    #if len(ccds) > 0:
    #    ccds = vstack(ccds)
    #    fcat = vstack(fcat)
    #print(f'Final sample: {len(fcat):,d}/{len(indx_cat):,d} objects and {len(ccds):,d} CCDs.')
    #return fcat, ccds

    if comm:
        fcat = comm.gather(fcat, root=0)

    # sort and return
    if rank == 0:
        fcat = vstack(fcat)

        print(f'Rank {rank:03d}: Final sample: {len(fcat):,d}/{len(indx_cat):,d} objects.')
        
        fcat = fcat[match_to(fcat['ROW'], cat['ROW'])]
        print(f'Rank {rank:03d}: Total time: {(time.time()-t0)/60.:.3f} min')
        return fcat


def main():
    """Main wrapper

    """
    import argparse
    from legacypipe.runs import get_survey

    regions = ['north', 'south']
    catalogs = ['HyperLeda', 'NEDLVS', 'WXSC', 'LVD'] # 'HECATE', 'Z0MGS']

    parser = argparse.ArgumentParser()
    parser.add_argument('--merge', action='store_true', help='Merge into a single, final parent catalog.')
    parser.add_argument('--region', choices=regions, type=str, nargs='*', help='Region to pass to --in-footprint.')
    parser.add_argument('--catalog', choices=catalogs, type=str, help='External catalog to pass to --in-footprint.')
    parser.add_argument('--in-footprint', action='store_true', help='Match the various external catalogs to the CCDs files.')
    parser.add_argument('--overwrite', action='store_true', help='Overwrite existing files.')
    parser.add_argument('--mp', default=1, type=int, help='Number of multiprocessing processes per MPI rank.')
    args = parser.parse_args()

    # https://docs.nersc.gov/development/languages/python/parallel-python/#use-the-spawn-start-method
    if args.mp > 1 and 'NERSC_HOST' in os.environ:
        import multiprocessing
        multiprocessing.set_start_method('spawn')

    try:
        from mpi4py import MPI
        from mpi4py.util import pkl5
        #comm = MPI.COMM_WORLD
        comm = pkl5.Intracomm(MPI.COMM_WORLD)
    except ImportError:
        comm = None

    if comm is None:
        rank, size = 0, 1
    else:
        rank, size = comm.rank, comm.size

    footdir = os.path.join(basedir, 'parent', 'in-footprint')
    if args.in_footprint:
        if not os.path.isdir(footdir):
            os.makedirs(footdir)

        for region in np.atleast_1d(args.region):
            survey = get_survey(region)#, allbands=BANDS)
            _ = survey.get_ccds_readonly()

            for catalog in np.atleast_1d(args.catalog):
                outfile = os.path.join(footdir, f'{catalog}-{region}.fits')
                qafile = os.path.join(footdir, f'qa-{catalog}-{region}.png')
                if rank == 0:
                    print(f'Rank {rank:03d}: Working on region={region} and catalog={catalog}')
                    fullcat = read_cat(catalog)
                else:
                    fullcat = Table()

                if comm:
                    fullcat = comm.bcast(fullcat, root=0)        
                    
                if not os.path.isfile(outfile) or args.overwrite:
                    cat = in_footprint(fullcat, allccds=survey.ccds, bands=None, comm=comm, mp=1)#=args.mp)
                    # write out
                    if rank == 0:
                        nccds = np.sum(cat['NCCD'])
                        print(f'Rank {rank:03d}: Writing {len(cat):,d} objects with {nccds:,d} CCDs to {outfile}')
                        #print(f'Writing {len(cat):,d} objects and {len(ccds):,d} CCDs to {outfile}')
                        fitsio.write(outfile, cat.as_array(), extname='CATALOG', clobber=True)
                        #fitsio.write(outfile, ccds.as_array(), extname='CCDS')
                else:
                    if rank == 0:
                        cat = Table(fitsio.read(outfile, ext='CATALOG'))
                        #ccds = Table(fitsio.read(outfile, ext='CCDS'))
                        print(f'Rank {rank:03d}: Read {len(cat):,d} objects from {outfile}')
    
                if rank == 0:
                    # simple QA
                    import matplotlib.pyplot as plt
                    import seaborn as sns
                    
                    if len(fullcat) < 1e3:
                        s = 20
                        markerscale = 1
                    else:
                        s = 1
                        markerscale = 10
                    fig, ax = plt.subplots(figsize=(8, 6))
                    ax.scatter(fullcat['RA'], fullcat['DEC'], s=s, color='gray')
                    for bands in sorted(set(cat['FILTERS'])):
                        I = cat['FILTERS'] == bands
                        ax.scatter(cat['RA'][I], cat['DEC'][I], s=s, alpha=0.7, label=f'{bands} (N={np.sum(I):,d})')
                    ax.set_xlabel('RA')
                    ax.set_ylabel('Dec')
                    ax.set_xlim(360., 0.)
                    ax.set_ylim(-90., 90.)
                    #ax.invert_xaxis()
                    ax.legend(fontsize=10, ncols=2, markerscale=markerscale, loc='lower left')
                    fig.tight_layout()
                    fig.savefig(qafile)
                    print(f'Rank {rank:03d}: Wrote {qafile}')


    if args.merge:
        # What's missing?

        #region = 'south'
        region = 'north'
        cat = Table(fitsio.read(os.path.join(footdir, f'LVD-{region}.fits'), 'CATALOG'))
        cat = add_pgc(cat, 'lvd')
        

        pdb.set_trace()
        
        cat = Table(fitsio.read(os.path.join(footdir, f'NEDLVS-{region}.fits'), 'CATALOG'))
        refcat = Table(fitsio.read(os.path.join(footdir, f'HyperLeda-{region}.fits'), 'CATALOG'))

        #info = domatch_pgc(cat, refcat)
        info = domatch_coord(cat, refcat)

        pdb.set_trace()
        
        cat = read_lvd()
        cc = cat[cat['PGC'] == 0]['NAME', 'RA', 'DEC', 'CONFIRMED_REAL', 'REF_STRUCTURE']
        for oo in cc:
            print(f'{oo["NAME"]} {oo["RA"]}d {oo["DEC"]}d 0.5')

        ned = read_nedlvs()
        I = [indx for indx, gg in enumerate(ned['OBJNAME']) if 'bootes' in gg.lower()]
        
        pdb.set_trace()


if __name__ == '__main__':
    main()
