#!/usr/bin/env python 

"""Code to build the parent SGA2024 sample based on a combination of internal and external catalogs.

"""
import pdb # for debugging

import os
import numpy as np
import numpy.ma as ma
import fitsio
import multiprocessing
from astropy.table import Table, vstack
import matplotlib.pyplot as plt

import SGA.io
from SGA.coadds import PIXSCALE, BANDS

basedir = SGA.io.sga_dir()

#from astroquery.ipac.ned import Ned
#qq = Ned.query_object("UM198")
#qq = Ned.get_table('um198', table='diameters')


def read_wxsc():
    """Read the WXSC catalog.

    """
    wxscfile = os.path.join(basedir, 'parent', 'external', 'WXSC_Riso_W1mag_24Jun024.tbl') # 'WXSC_Riso_1arcmin_10Jun2024.tbl')
    wxsc = Table.read(wxscfile, format='ascii.ipac')
    wxsc['ROW'] = np.arange(len(wxsc))
    print(f'Read {len(wxsc):,d} objects from {wxscfile}')

    # toss out duplicates
    radec = np.array([f'{ra}-{dec}' for ra, dec in zip(wxsc['ra'].astype(str), wxsc['dec'].astype(str))])
    u, c = np.unique(radec, return_counts=True)

    _, uindx = np.unique(radec, return_index=True)    
    
    print(f'Trimming to {len(uindx):,d}/{len(wxsc):,d} unique objects based on (ra,dec)')
    wxsc = wxsc[uindx]

    _, uindx = np.unique(wxsc['NED_name'], return_index=True)
    print(f'WARNING: Trimming to {len(uindx):,d}/{len(wxsc):,d} unique objects based on NED name')
    wxsc = wxsc[uindx]

    #u, c = np.unique(wxsc['NED_name'], return_counts=True)
    #print(np.unique(c))
    #dup = vstack([wxsc[wxsc['NED_name'] == gal] for gal in u[c>1]])
    #return dup

    [wxsc.rename_column(col, col.upper()) for col in wxsc.colnames]
    wxsc['GALAXY'] = wxsc['WXSCNAME']

    #plt.clf() ; plt.hist(np.log10(bb['Riso']), bins=100) ; plt.savefig('junk.png')

    return wxsc


def read_hyperleda():
    """Read the HyperLeda catalog.

    """
    hyperfile = os.path.join(basedir, 'parent', 'external', 'HyperLeda_meandata_1718379336.txt')

    with open(hyperfile, 'r') as F:
        nrows = len(F.readlines())
    
    hyper = Table.read(hyperfile, format='ascii.csv', data_start=22,
                       data_end=nrows-5, header_start=20)
    [hyper.rename_column(col, col.upper()) for col in hyper.colnames]
    hyper['ROW'] = np.arange(len(hyper))

    hyper.rename_columns(['AL2000', 'DE2000'], ['RA', 'DEC'])
    hyper['RA'] *= 15. # [decimal degrees]
    
    nhyper = len(hyper)
    print(f'Read {nhyper:,d} objects from {hyperfile}')
    assert(nhyper == len(np.unique(hyper['PGC'])))

    ## objects with all three of diameter, Bt-mag, and redshift
    #J = np.logical_and.reduce((hyper['LOGD25'].mask, hyper['BT'].mask, hyper['v'].mask))
    #
    ## objects with *none* of diameter, Bt-mag, or redshift, which are most likely to be stars or spurious
    #I = np.logical_or.reduce((~hyper['LOGD25'].mask, ~hyper['BT'].mask, ~hyper['v'].mask))

    return hyper


def read_cat(catname):
    """Wrapper to read one of the known external catalogs.

    """
    match catname.lower():
        case 'wxsc':
            cat = read_wxsc()
        case 'hyperleda':
            cat = read_hyperleda()
        case _:
            raise ValueError(f'Unrecognized catalog name {catname}')

    return cat


def _get_ccds(args):
    """Wrapper for the multiprocessing."""
    return get_ccds(*args)


def get_ccds(counter, allccds, ra, dec, row, width_pixels, pixscale=PIXSCALE):
    """Quickly get the CCDs touching this custom brick.  This code is mostly taken
    from legacypipe.runbrick.stage_tims.

    """
    from SGA.coadds import custom_brickname
    from legacypipe.survey import wcs_for_brick, BrickDuck, ccds_touching_wcs

    #print(counter)
    
    brickname = f'custom-{custom_brickname(ra, dec)}'
    brick = BrickDuck(ra, dec, brickname)

    targetwcs = wcs_for_brick(brick, W=float(width_pixels), H=float(width_pixels), pixscale=pixscale)
    I = ccds_touching_wcs(targetwcs, allccds)
    #ccds = survey.ccds_touching_wcs(targetwcs)
    #print(len(I))

    if len(I) == 0:
        return Table()

    ccds = allccds[I]

    # convert to an astropy Table so we can vstack
    _ccds = ccds.to_dict()
    ccds = Table()
    for key in _ccds.keys():
        ccds[key.upper()] = _ccds[key]

    ccds = ccds['CAMERA', 'EXPNUM', 'PLVER', 'CCDNAME', 'FILTER']
    #ccds['GALAXY'] = [galaxy]
    ccds['ROW'] = [row]
    
    return ccds


def in_footprint(cat, allccds, radius=1., width_pixels=152, bands=BANDS, mp=1):
    """Find which objects are in the given survey footprint based on positional
    matching with a very generous (1 deg) search radius.

    radius in degrees

    """
    from astrometry.libkd.spherematch import match_radec

    # I, which has len(cat), is the index into allccds of the matches, or None
    # if no match (which we immediately filter out).
    I = match_radec(cat['RA'], cat['DEC'], allccds.ra, allccds.dec,
                    radius, indexlist=True)
    M = [indx for indx, val in enumerate(I) if val is not None]
    print(f'Found {len(M):,d}/{len(cat):,d} objects with at least one CCD within {radius} deg.')

    # now perform a more refined search for each matching object
    mpargs = []
    for icat, catindx in enumerate(M):
        mpargs.append([icat, allccds[I[catindx]], cat[catindx]['RA'], cat[catindx]['DEC'],
                       cat[catindx]['ROW'], width_pixels, PIXSCALE])

    if mp > 1:
        with multiprocessing.Pool(mp) as P:
            ccds = P.map(_get_ccds, mpargs)
    else:
        ccds = [_get_ccds(_mpargs) for _mpargs in mpargs]
        
    if len(ccds) > 0:
        ccds = vstack(ccds)    

    urows = np.sort(np.unique(ccds['ROW']))
    fcat = cat[np.isin(cat['ROW'], urows)]
    print(f'Final sample: {len(fcat):,d}/{len(M):,d} objects and {len(ccds):,d} CCDs.')

    nccd = np.zeros(len(fcat), int)
    filters = np.zeros(len(fcat), '<U4')
    for iobj, row in enumerate(fcat['ROW']):
        nccd[iobj] = np.sum(ccds['ROW'] == row)
        filters[iobj] = ''.join(sorted(set(ccds[ccds['ROW'] == row]['FILTER'])))
    fcat['NCCD'] = nccd
    fcat['FILTERS'] = filters

    return ccds, fcat


def main():
    """Main wrapper

    """
    import argparse
    from legacypipe.runs import get_survey

    parser = argparse.ArgumentParser()
    parser.add_argument('--in-footprint', action='store_true', help='Match the various external catalogs to the CCDs files.')
    parser.add_argument('--overwrite', action='store_true', help='Overwrite existing files.')
    parser.add_argument('--mp', default=1, type=int, help='Number of multiprocessing processes per MPI rank.')
    args = parser.parse_args()

    # https://docs.nersc.gov/development/languages/python/parallel-python/#use-the-spawn-start-method
    if args.mp > 1 and 'NERSC_HOST' in os.environ:
        import multiprocessing
        multiprocessing.set_start_method('spawn')

    if args.in_footprint:
        outdir = os.path.join(basedir, 'parent', 'in-footprint')
        if not os.path.isdir(outdir):
            os.makedirs(outdir)
        
        #for run in ['south', 'north']:
        for run in ['north', 'south']:
            survey = get_survey(run)#, allbands=BANDS)
            # populate the ccds and ccd_kdtrees cache
            _ = survey.get_ccds_readonly()
            _ = survey.get_ccd_kdtrees()   
            #for catname in ['WXSC']:#, ]:#, 'LVS', 'HECATE', 'LVD', 'z0MGS']:
            for catname in ['HyperLeda']:#, 'WXSC']:#, 'LVS', 'HECATE', 'LVD', 'z0MGS']:
                print(f'Working on run={run} and catalog={catname}')
                outfile = os.path.join(outdir, f'{catname}-{run}.fits')
                qafile = os.path.join(outdir, f'qa-{catname}-{run}.png')
                fullcat = read_cat(catname)
                if not os.path.isfile(outfile) or args.overwrite:
                    ccds, cat = in_footprint(fullcat, allccds=survey.ccds, bands=None, mp=args.mp)
                    # write out
                    print(f'Writing {len(cat):,d} objects and {len(ccds):,d} to {outfile}')
                    fitsio.write(outfile, cat.as_array(), extname='CATALOG', clobber=True)
                    fitsio.write(outfile, ccds.as_array(), extname='CCDS')
                else:
                    cat = Table(fitsio.read(outfile, ext='CATALOG'))
                    ccds = Table(fitsio.read(outfile, ext='CCDS'))
                    print(f'Read {len(cat):,d} objects and {len(ccds)} from {outfile}')

                # simple QA
                fig, ax = plt.subplots(figsize=(8, 6))
                ax.scatter(fullcat['RA'], fullcat['DEC'], s=1, color='gray')
                for bands in sorted(set(cat['FILTERS'])):
                    I = cat['FILTERS'] == bands
                    ax.scatter(cat['RA'][I], cat['DEC'][I], s=1, alpha=0.7, label=f'{bands} (N={np.sum(I):,d})')
                ax.set_xlabel('RA')
                ax.set_ylabel('Dec')
                ax.set_xlim(360., 0.)
                ax.set_ylim(-90., 90.)
                #ax.invert_xaxis()
                ax.legend(fontsize=10, ncols=2, markerscale=10, loc='lower left')
                fig.tight_layout()
                fig.savefig(qafile)
                print(f'Wrote {qafile}')

        pdb.set_trace()

if __name__ == '__main__':
    main()
