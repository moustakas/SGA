#!/usr/bin/env python

"""Code to build the parent SGA2024 sample based on a combination of internal and external catalogs.

SGA2024-build-parent --in-footprint --mp 128 --overwrite

"""
import pdb # for debugging

import os, time
import numpy as np
import numpy.ma as ma
import fitsio
from astropy.table import Table, vstack, hstack, join

import SGA.io
from SGA.coadds import PIXSCALE, BANDS

basedir = SGA.io.sga_dir()

#from astroquery.ipac.ned import Ned
#qq = Ned.query_object("UM198")
#qq = Ned.get_table('um198', table='diameters')


def domatch_pgc(cat, refcat, rank=0):
    """Match a catalog and a reference catalog based on PGC number and then positionally.

    """
    import astropy.units as u
    from astropy.coordinates import SkyCoord
    from SGA.util import match

    # match on PGC
    if 'PGC' in cat.colnames:
        indx_cat, indx_refcat = match(cat['PGC'], refcat['PGC'])
        print(f'Rank {rank:03d}: Matched {len(indx_cat):,d}/{len(cat):,d} objects based on PGC number.')

        refcols = ['PGC', 'OBJNAME', 'RA', 'DEC', 'LOGD25', 'PA']
        cols = ['PGC', 'GALAXY', 'RA', 'DEC', 'RHALF', 'POSITION_ANGLE', 'ELLIPTICITY', 'SURFACE_BRIGHTNESS_RHALF']
        info = join(refcat[refcols][indx_refcat], cat[cols][indx_cat], keys='PGC',
                    table_names=['REFCAT', 'CAT'])
        print(info[np.argsort(info['SEPARCSEC'])[::-1]])
        
    # match on coordinates
    nopgc = np.where(cat['PGC'] == -1)[0]
    if len(nopgc) > 0:
        print('Rank {rank:03d}: Matching based on coordinates.')
        c_cat = SkyCoord(cat['RA'][nopgc]*u.deg, cat['DEC'][nopgc]*u.deg)
        c_refcat = SkyCoord(refcat['RA']*u.deg, refcat['DEC']*u.deg)
        indx_refcat, sep2d, _ = c_cat.match_to_catalog_sky(c_refcat)
        print(f'Rank {rank:03d}: Mean and max separation between {len(cat)} galaxies is ' \
              '{np.mean(sep2d.arcsec):.3f}+/-{np.std(sep2d.arcsec):.3f}, {np.max(sep2d.arcsec):.3f} arcsec.')

        pdb.set_trace()

        info = hstack((refcat[indx_refcat]['PGC', 'OBJNAME', 'RA', 'DEC', 'LOGD25'], cat['GALAXY', 'RA', 'DEC', 'RHALF', 'SURFACE_BRIGHTNESS_RHALF']))
        info['SEPARCSEC'] = sep2d.arcsec.astype('f4')
    
    pdb.set_trace()


def domatch_coord(cat, refcat, rank=0):
    """Match a catalog and a reference catalog based coordinates.

    """
    import astropy.units as u
    from astropy.coordinates import SkyCoord
    from SGA.util import match

    print('Rank {rank:03d}: Matching based on coordinates.')
    c_cat = SkyCoord(cat['RA']*u.deg, cat['DEC']*u.deg)
    c_refcat = SkyCoord(refcat['RA']*u.deg, refcat['DEC']*u.deg)
    indx_refcat, sep2d, _ = c_cat.match_to_catalog_sky(c_refcat)
    print(f'Rank {rank:03d}: Mean and max separation between {len(cat)} galaxies is ' \
          f'{np.mean(sep2d.arcsec):.3f}+/-{np.std(sep2d.arcsec):.3f}, {np.max(sep2d.arcsec):.3f} arcsec.')

    srt = np.argsort(sep2d)[::-1]
    refcat[indx_refcat[srt]][:10]
    cat[srt][:10]
    
          
    pdb.set_trace()

    info = hstack((refcat[indx_refcat]['PGC', 'OBJNAME', 'RA', 'DEC', 'LOGD25'], cat['GALAXY', 'RA', 'DEC', 'RHALF', 'SURFACE_BRIGHTNESS_RHALF']))
    info['SEPARCSEC'] = sep2d.arcsec.astype('f4')
    
    pdb.set_trace()


def add_pgc(cat, catname):
    """Add PGC numbers to the various samples.

    """
    # 0 = not in HyperLeda; -1 not checked yet
    cat['PGC'] = np.zeros(len(cat), int) - 1

    if catname.lower() == 'lvd':
        # http://atlas.obs-hp.fr/hyperleda/fG.cgi?c=o&n=a000&s=hc1719669736 - north
        # http://atlas.obs-hp.fr/hyperleda/fG.cgi?c=o&n=a000&s=hc1719674256 - south

        # PGC1198787 = KKR53 ???
        # PGC1330929 = KKR33 ??
        # PGC200320 = KKR13 ??
        # PGC2801041 = KKR43 ??
        # PGC2801056 = KKR63
        # PGC2801063 = KKR73
        # PGC57522 = KKR23
        pgc = {
            # north
            'Bootes IV': 0, 
            'Canes Venatici II': 4713558, 
            'Draco': 60095, 
            'Draco II': 0, 
            'Ursa Major I': 4713554, 
            'Ursa Major II': 4713555, 
            'Ursa Minor': 54074, 
            'Willman 1': 4713556, 
            'M 32': 2555, 
            'NGC 205': 2429, 
            'DDO 44': 21302, 
            'DDO 99': 37050, 
            'DDO 113': 39145, 
            'DDO 125': 40904, 
            'DDO 147': 43129, 
            'DDO 190': 51472, 
            'KKR 25': 2801026, 
            'KKR 3': 166185,
            'Leo A': 28868,  # =Leo 3
            'NGC 4163': 38881, 
            'NGC 4190': 39023, 
            'NGC 4214': 39225, 
            'UGC 4879': 26142, 
            'UGC 8508': 47495,
            # south
            'Aquarius II': 5953206,
            'Bootes I': 4713553,
            'Bootes II': 4713552,
            'Bootes III': 4713562,
            'Bootes V': 0,
            'Canes Venatici I': 4689223,
            'Cetus II': 6740632,
            'Cetus III': 6726344,
            'Columba I': 6740626,
            'Coma Berenices': 0,
            'Eridanus II': 5074553,
            'Fornax': 10074,
            'Grus I': 5074558,
            'Grus II': 6740630,
            'Hercules': 4713560,
            'Horologium I': 5074554,
            'Horologium II': 5092747,
            'Leo I': 29488,
            'Leo II': 34176, # = Leo B
            'Leo IV': 4713561,
            'Leo V': 4713563,
            'Leo Minor I': 0,
            'Pegasus III': 5074547,
            'Pegasus IV': 0,
            'Phoenix II': 5074556,
            'Pictor I': 0,
            'Pisces II': 5056949,
            'Reticulum II': 5074552,
            'Reticulum III': 6740628,
            'Sculptor': 3589,
            'Segue 1': 4713559,
            'Segue 2': 4713565,
            'Sextans': 0,
            'Sextans II': 0,
            'Tucana II': 5074560,
            'Tucana III': 6657034,
            'Tucana IV': 6740629,
            'Tucana V': 6740631,
            'Ursa Major III': 0, # discovered in 2024
            'Virgo I': 6657032,
            'Virgo II': 0,
            'Virgo III': 0,
            'Andromeda II': 4601,
            'Andromeda VI': 2807158,
            'Andromeda XIII': 5056925,
            'Andromeda XIV': 5056922,
            'Andromeda XVI': 5056927,
            'Andromeda XXII': 5057232,
            'Andromeda XXVIII': 5060429,
            'Andromeda XXIX': 5060430,
            'LGS 3': 3792,
            'Pegasus V': 0,
            'Pisces VII': 0,
            'AGC749235': 5059199,
            'Antlia': 29194,
            'Antlia B': 5098252,
            'Cetus': 3097691,
            'ESO 294-G010': 1641,
            'ESO 410-G005': 1038,
            'GR 8': 44491,
            'IC 1613': 3844,
            'IC 5152': 67908,
            'KKH 86': 2807150,
            'Leo K': 0,
            'Leo M': 0,
            'Leo P': 5065058,
            'Leo T': 4713564,
            'NGC 55': 1014,
            'NGC 55-dw1': 0,
            'NGC 300': 3238,
            'NGC 3109': 29128,
            'Pegasus dIrr': 0, # = Pegasus 1 (not in NED)
            'Pegasus W': 0, # in NED
            'Phoenix': 6830,
            'Sextans A': 29653,
            'Sextans B': 28913,
            'Tucana': 69519,
            'Tucana B': 0, # = SMDG J2247005-582429
            'UGC 9128': 50961,
            }

    for key in pgc.keys():
        I = np.where(cat['GALAXY'] == key)[0]
        if len(I) == 0:
            #raise ValueError(f'Error in galaxy name {key}')
            continue
        cat['PGC'][I] = pgc[key]

    ## add NED names, so we can match against the NED-LVS
    #ned = {'Bootes IV': 'Bootes IV Dwarf', # not in NED-LVS
    #       'Coma Berenices': 'Coma Berenices Dwarf',
    #       'Draco II': 'Draco II',
    #       }

    return cat


def read_lvd(rank=0):
    """Read the Local Volume Database (LVD) dwarf-galaxy catalog.

    """
    lvdfile = os.path.join(basedir, 'parent', 'external', 'LVD-dwarf-all-b685634.fits')
    lvd = Table(fitsio.read(lvdfile))
    lvd['ROW'] = np.arange(len(lvd))
    print(f'Rank {rank:03d}: Read {len(lvd):,d} objects from {lvdfile}')

    [lvd.rename_column(col, col.upper()) for col in lvd.colnames]
    lvd['GALAXY'] = lvd['NAME']

    return lvd


def read_nedlvs(rank=0):
    """Read the NED-LVS catalog.

    """
    nedlvsfile = os.path.join(basedir, 'parent', 'external', 'NEDLVS_20210922_v2.fits')
    nedlvs = Table(fitsio.read(nedlvsfile))
    nedlvs['ROW'] = np.arange(len(nedlvs))
    print(f'Rank {rank:03d}: Read {len(nedlvs):,d} objects from {nedlvsfile}')

    [nedlvs.rename_column(col, col.upper()) for col in nedlvs.colnames]
    nedlvs['GALAXY'] = nedlvs['OBJNAME']

    return nedlvs


def read_wxsc(rank=0):
    """Read the WXSC catalog.

    """
    wxscfile = os.path.join(basedir, 'parent', 'external', 'WXSC_Riso_W1mag_24Jun024.tbl') # 'WXSC_Riso_1arcmin_10Jun2024.tbl')
    wxsc = Table.read(wxscfile, format='ascii.ipac')
    wxsc['ROW'] = np.arange(len(wxsc))
    print(f'Rank {rank:03d}: Read {len(wxsc):,d} objects from {wxscfile}')

    # toss out duplicates
    radec = np.array([f'{ra}-{dec}' for ra, dec in zip(wxsc['ra'].astype(str), wxsc['dec'].astype(str))])
    u, c = np.unique(radec, return_counts=True)

    _, uindx = np.unique(radec, return_index=True)    
    
    print(f'Rank {rank:03d}: Trimming to {len(uindx):,d}/{len(wxsc):,d} unique objects based on (ra,dec)')
    wxsc = wxsc[uindx]

    _, uindx = np.unique(wxsc['NED_name'], return_index=True)
    print(f'Rank {rank:03d}: WARNING: Trimming to {len(uindx):,d}/{len(wxsc):,d} unique objects based on NED name')
    wxsc = wxsc[uindx]

    #u, c = np.unique(wxsc['NED_name'], return_counts=True)
    #print(np.unique(c))
    #dup = vstack([wxsc[wxsc['NED_name'] == gal] for gal in u[c>1]])
    #return dup

    [wxsc.rename_column(col, col.upper()) for col in wxsc.colnames]
    wxsc['GALAXY'] = wxsc['WXSCNAME']

    return wxsc


def read_cat(catalog):
    """Wrapper to read one of the known external catalogs.

    """
    match catalog.lower():
        case 'hyperleda':
            from SGA.io import read_hyperleda
            cat = read_hyperleda()
        case 'wxsc':
            cat = read_wxsc()
        case 'nedlvs':
            cat = read_nedlvs()
        case 'lvd':
            cat = read_lvd()
        case _:
            raise ValueError(f'Unrecognized catalog name {catalog}')

    return cat


#def _get_ccds(args):
#    """Wrapper for the multiprocessing."""
#    return get_ccds(*args)


def get_ccds(allccds, onegal, width_pixels, pixscale=PIXSCALE, return_ccds=False):
    """Quickly get the CCDs touching this custom brick.  This code is mostly taken
    from legacypipe.runbrick.stage_tims.

    """
    from SGA.coadds import custom_brickname
    from legacypipe.survey import wcs_for_brick, BrickDuck, ccds_touching_wcs

    brickname = f'custom-{custom_brickname(onegal["RA"], onegal["DEC"])}'
    brick = BrickDuck(onegal['RA'], onegal['DEC'], brickname)

    targetwcs = wcs_for_brick(brick, W=float(width_pixels), H=float(width_pixels), pixscale=pixscale)
    I = ccds_touching_wcs(targetwcs, allccds)
    #ccds = survey.ccds_touching_wcs(targetwcs)
    #print(len(I))

    # no CCDs within width_pixels
    if len(I) == 0:
        if return_ccds:
            return Table(), Table()
        else:
            return Table()

    ccds = allccds[I]

    onegal['NCCD'] = len(ccds)
    onegal['FILTERS'] = ''.join(sorted(set(ccds.filter)))
    
    if return_ccds:
        # convert to an astropy Table so we can vstack
        _ccds = ccds.to_dict()
        ccds = Table()
        for key in _ccds.keys():
            ccds[key.upper()] = _ccds[key]

        ccds = ccds['RA', 'DEC', 'CAMERA', 'EXPNUM', 'PLVER', 'CCDNAME', 'FILTER']
        #ccds['GALAXY'] = [galaxy]
        ccds['ROW'] = onegal['ROW']

        return ccds, Table(onegal)
    else:
        return Table(onegal)


def in_footprint(cat, allccds, radius=1., width_pixels=152, bands=BANDS, comm=None, mp=1):
    """Find which objects are in the given survey footprint based on positional
    matching with a very generous (1 deg) search radius.

    radius in degrees

    """
    from astrometry.libkd.spherematch import match_radec
    from SGA.util import weighted_partition, match_to

    if comm is None:
        rank, size = 0, 1
    else:
        rank, size = comm.rank, comm.size

    cat['NCCD'] = np.zeros(len(cat), int)
    cat['FILTERS'] = np.zeros(len(cat), '<U4')

    if rank == 0:
        t0 = time.time()

        # I, which is a list of len(cat), is the variable-length of indices into
        # allccds of the matches, or None if no match (which we filter out).
        indx_ccds = match_radec(cat['RA'], cat['DEC'], allccds.ra, allccds.dec,
                                radius, indexlist=True)

        indx_cat = []
        nccdperobj = []
        for icat, val in enumerate(indx_ccds):
            if val is not None:
                indx_cat.append(icat)
                nccdperobj.append(len(indx_ccds[icat]))
        print(f'Rank {rank:03d}: Found {len(indx_cat):,d}/{len(cat):,d} objects with at least one CCD within {radius} deg.')

        groups = weighted_partition(nccdperobj, size)
    else:
        indx_cat = []
        indx_ccds = []
        groups = [np.array([])]

    # broadcast the work to the other ranks
    if comm:
        indx_cat = comm.bcast(indx_cat, root=0)
        indx_ccds = comm.bcast(indx_ccds, root=0)
        groups = comm.bcast(groups, root=0)

    # now perform a more refined search for each matching object
    
    fcat = []
    #ccds = []
    for icat, indx in enumerate(groups[rank]):
        catindx = indx_cat[indx]
        onegal = cat[catindx]
        if icat % len(groups[rank]) == 0 or icat+1 == len(groups[rank]):
            print(f'Rank {rank:03d}: Working on galaxy: {icat+1:,d}/{len(groups[rank])}')
        #print(f'Rank {rank:03d} working on galaxy: {onegal["GALAXY"]}')
        one_fcat = get_ccds(allccds[indx_ccds[catindx]], onegal, width_pixels,
                            pixscale=PIXSCALE, return_ccds=False)
        fcat.append(one_fcat)

    if len(fcat) > 0:
        fcat = vstack(fcat)
        
    #mpargs = []
    #for icat, catindx in enumerate(M):
    #    mpargs.append([icat, allccds[I[catindx]], cat[catindx], width_pixels, PIXSCALE])
    #
    #if mp > 1:
    #    import multiprocessing
    #    with multiprocessing.Pool(mp) as P:
    #        out = P.map(_get_ccds, mpargs)
    #else:
    #    out = [_get_ccds(_mpargs) for _mpargs in mpargs]
    #out = list(zip(*out))
    #
    #ccds = out[0]
    #fcat = out[1]
    #if len(ccds) > 0:
    #    ccds = vstack(ccds)
    #    fcat = vstack(fcat)
    #print(f'Final sample: {len(fcat):,d}/{len(indx_cat):,d} objects and {len(ccds):,d} CCDs.')
    #return fcat, ccds

    if comm:
        fcat = comm.gather(fcat, root=0)

    # sort and return
    if rank == 0:
        fcat = vstack(fcat)

        print(f'Rank {rank:03d}: Final sample: {len(fcat):,d}/{len(indx_cat):,d} objects.')
        
        fcat = fcat[match_to(fcat['ROW'], cat['ROW'])]
        print(f'Rank {rank:03d}: Total time: {(time.time()-t0)/60.:.3f} min')
        return fcat


def main():
    """Main wrapper

    """
    import argparse
    from legacypipe.runs import get_survey

    regions = ['north', 'south']
    catalogs = ['HyperLeda', 'NEDLVS', 'WXSC', 'LVD'] # 'HECATE', 'Z0MGS']

    parser = argparse.ArgumentParser()
    parser.add_argument('--merge', action='store_true', help='Merge into a single, final parent catalog.')
    parser.add_argument('--region', choices=regions, type=str, nargs='*', help='Region to pass to --in-footprint.')
    parser.add_argument('--catalog', choices=catalogs, type=str, help='External catalog to pass to --in-footprint.')
    parser.add_argument('--in-footprint', action='store_true', help='Match the various external catalogs to the CCDs files.')
    parser.add_argument('--overwrite', action='store_true', help='Overwrite existing files.')
    parser.add_argument('--mp', default=1, type=int, help='Number of multiprocessing processes per MPI rank.')
    args = parser.parse_args()

    # https://docs.nersc.gov/development/languages/python/parallel-python/#use-the-spawn-start-method
    if args.mp > 1 and 'NERSC_HOST' in os.environ:
        import multiprocessing
        multiprocessing.set_start_method('spawn')

    try:
        from mpi4py import MPI
        from mpi4py.util import pkl5
        #comm = MPI.COMM_WORLD
        comm = pkl5.Intracomm(MPI.COMM_WORLD)
    except ImportError:
        comm = None

    if comm is None:
        rank, size = 0, 1
    else:
        rank, size = comm.rank, comm.size

    footdir = os.path.join(basedir, 'parent', 'in-footprint')
    if args.in_footprint:
        if not os.path.isdir(footdir):
            os.makedirs(footdir)

        for region in np.atleast_1d(args.region):
            survey = get_survey(region)#, allbands=BANDS)
            _ = survey.get_ccds_readonly()

            for catalog in np.atleast_1d(args.catalog):
                outfile = os.path.join(footdir, f'{catalog}-{region}.fits')
                qafile = os.path.join(footdir, f'qa-{catalog}-{region}.png')
                if rank == 0:
                    print(f'Rank {rank:03d}: Working on region={region} and catalog={catalog}')
                    fullcat = read_cat(catalog)
                else:
                    fullcat = Table()

                if comm:
                    fullcat = comm.bcast(fullcat, root=0)        
                    
                if not os.path.isfile(outfile) or args.overwrite:
                    cat = in_footprint(fullcat, allccds=survey.ccds, bands=None, comm=comm, mp=1)#=args.mp)
                    # write out
                    if rank == 0:
                        nccds = np.sum(cat['NCCD'])
                        print(f'Rank {rank:03d}: Writing {len(cat):,d} objects with {nccds:,d} CCDs to {outfile}')
                        #print(f'Writing {len(cat):,d} objects and {len(ccds):,d} CCDs to {outfile}')
                        fitsio.write(outfile, cat.as_array(), extname='CATALOG', clobber=True)
                        #fitsio.write(outfile, ccds.as_array(), extname='CCDS')
                else:
                    if rank == 0:
                        cat = Table(fitsio.read(outfile, ext='CATALOG'))
                        #ccds = Table(fitsio.read(outfile, ext='CCDS'))
                        print(f'Rank {rank:03d}: Read {len(cat):,d} objects from {outfile}')
    
                if rank == 0:
                    # simple QA
                    import matplotlib.pyplot as plt
                    import seaborn as sns
                    
                    if len(fullcat) < 1e3:
                        s = 20
                        markerscale = 1
                    else:
                        s = 1
                        markerscale = 10
                    fig, ax = plt.subplots(figsize=(8, 6))
                    ax.scatter(fullcat['RA'], fullcat['DEC'], s=s, color='gray')
                    for bands in sorted(set(cat['FILTERS'])):
                        I = cat['FILTERS'] == bands
                        ax.scatter(cat['RA'][I], cat['DEC'][I], s=s, alpha=0.7, label=f'{bands} (N={np.sum(I):,d})')
                    ax.set_xlabel('RA')
                    ax.set_ylabel('Dec')
                    ax.set_xlim(360., 0.)
                    ax.set_ylim(-90., 90.)
                    #ax.invert_xaxis()
                    ax.legend(fontsize=10, ncols=2, markerscale=markerscale, loc='lower left')
                    fig.tight_layout()
                    fig.savefig(qafile)
                    print(f'Rank {rank:03d}: Wrote {qafile}')


    if args.merge:
        # What's missing?

        #region = 'south'
        region = 'north'
        cat = Table(fitsio.read(os.path.join(footdir, f'LVD-{region}.fits'), 'CATALOG'))
        cat = add_pgc(cat, 'lvd')
        

        pdb.set_trace()
        
        cat = Table(fitsio.read(os.path.join(footdir, f'NEDLVS-{region}.fits'), 'CATALOG'))
        refcat = Table(fitsio.read(os.path.join(footdir, f'HyperLeda-{region}.fits'), 'CATALOG'))

        #info = domatch_pgc(cat, refcat)
        info = domatch_coord(cat, refcat)

        pdb.set_trace()
        
        cat = read_lvd()
        cc = cat[cat['PGC'] == 0]['NAME', 'RA', 'DEC', 'CONFIRMED_REAL', 'REF_STRUCTURE']
        for oo in cc:
            print(f'{oo["NAME"]} {oo["RA"]}d {oo["DEC"]}d 0.5')

        ned = read_nedlvs()
        I = [indx for indx, gg in enumerate(ned['OBJNAME']) if 'bootes' in gg.lower()]
        
        pdb.set_trace()


if __name__ == '__main__':
    main()
