#!/usr/bin/env python

"""MPI wrapper to get a large number of image cutouts.

Working interactively in a login node, one would do something like:

  salloc -N 1 -C cpu -A m3592 -t 04:00:00 --qos interactive
  shifter --image legacysurvey/sga:0.3 bash
  source $CFS/desicollab/users/ioannis/SGA/2025/scripts/SGA2025-shifter-env.sh

    or

  shifter --env-file=$CFS/desicollab/users/ioannis/SGA/2025/scripts/SGA2025-shifter-env.sh --image dstndstn/cutouts:dvsro4 bash
  SGA2025-cutouts --outdir=/pscratch/sd/i/ioannis/SGA2025/parent --catalog=sga2025-parent --region=dr9-north --mp=1
  SGA2025-cutouts --outdir=/pscratch/sd/i/ioannis/SGA2025/parent --catalog=sga2025-parent --region=dr9-north --mp=1 --annotate
  SGA2025-cutouts --outdir=/pscratch/sd/i/ioannis/SGA2025/parent --catalog=sga2025-parent --region=dr9-north --mp=1 --photo


Alternatively, in production, one would do:

  salloc -N 1 -C cpu -A m3592 -t 04:00:00 --qos interactive --image=docker:dstndstn/cutouts:dvsro4

  time srun --ntasks=32 shifter --env-file=$CFS/desicollab/users/ioannis/SGA/2025/scripts/SGA2025-shifter-env.sh \
    SGA2025-cutouts --outdir=/pscratch/sd/i/ioannis/SGA2025/cutouts/parent --catalog=sga2025-parent --region=dr9-north --mp=4 > \
    /pscratch/sd/i/ioannis/SGA2025/cutouts/SGA2025-cutouts-parent-dr9-north-native-JOBID.log 2>&1 &

  time srun --ntasks=32 shifter --env-file=$CFS/desicollab/users/ioannis/SGA/2025/scripts/SGA2025-shifter-env.sh \
    SGA2025-cutouts --outdir=/pscratch/sd/i/ioannis/SGA2025/cutouts/parent --catalog=sga2025-parent --region=dr9-north --mp=4 --rescale > \
    /pscratch/sd/i/ioannis/SGA2025/cutouts/SGA2025-cutouts-parent-dr9-north-rescale-JOBID.log 2>&1 &

###
To build the ssl-legacysurvey catalog:

  First generate the rescaled cutouts of everything:
    salloc -N 1 -C cpu -A m3592 -t 04:00:00 --qos interactive
    shifter --image dstndstn/cutouts:dvsro4 bash
    source $CFS/desicollab/users/ioannis/SGA/2025/scripts/SGA2025-shifter-env.sh

    SGA2025-cutouts --outdir=/pscratch/sd/i/ioannis/SGA2025/ssl --catalog=sga2025-parent --region=dr9-north --rescale --mp=128
    SGA2025-cutouts --outdir=/pscratch/sd/i/ioannis/SGA2025/ssl --catalog=sga2025-parent --region=dr9-north --rescale --mp=128

    source $CFS/desicollab/users/ioannis/SGA/2025/scripts/SGA2025-shifter-env.sh  Then build the HDF5 files:
    SGA2025-shifter
    source /global/homes/i/ioannis/code/git/SGA/bin/SGA2025/SGA2025-env

    SGA2025-cutouts --outdir=/pscratch/sd/i/ioannis/SGA2025/ssl --catalog=sga2025-parent --build-ssl --ssl-version=v4
    SGA2025-cutouts --outdir=/pscratch/sd/i/ioannis/SGA2025/ssl --catalog=sga2025-parent --build-ssl --ssl-version=v3
    SGA2025-cutouts --outdir=/pscratch/sd/i/ioannis/SGA2025/ssl --catalog=sga2025-parent --build-ssl --ssl-version=v2
    SGA2025-cutouts --outdir=/pscratch/sd/i/ioannis/SGA2025/ssl --catalog=sga2025-parent --build-ssl --ssl-version=v1

  Investigate...
    SGA2025-cutouts --outdir=/pscratch/sd/i/ioannis/SGA2025/ssl --catalog=sga2025-parent --ssl --ssl-version=v3 --rescale --annotate --region=dr11-south --mp=32
    SGA2025-cutouts --outdir=/pscratch/sd/i/ioannis/SGA2025/ssl --catalog=sga2025-parent --ssl --ssl-version=v3 --rescale --annotated-montage --region=dr11-south --mp=32

    ###
    SGA2025-cutouts --outdir=/pscratch/sd/i/ioannis/SGA2025/ssl --catalog=sga2025-parent --ssl --ssl-version=v1 --no-fits-cutouts --region=dr9-north --mp=32
    SGA2025-cutouts --outdir=/pscratch/sd/i/ioannis/SGA2025/ssl --catalog=sga2025-parent --ssl --ssl-version=v1 --rescale --annotated-montage --region=dr9-north

###
Kim's wisesize project:
  SGA2025-cutouts --outdir=/pscratch/sd/i/ioannis/SGA2025/wisesize --catalog=sga2025-parent --wisesize --region=dr9-north --mp=32
  SGA2025-cutouts --outdir=/pscratch/sd/i/ioannis/SGA2025/wisesize --catalog=sga2025-parent --wisesize --region=dr9-south --mp=32

  SGA2025-cutouts --outdir=/pscratch/sd/i/ioannis/SGA2025/wisesize --catalog=sga2025-parent --wisesize --region=dr9-north --annotate --annotate-central-only --mp=32
  SGA2025-cutouts --outdir=/pscratch/sd/i/ioannis/SGA2025/wisesize --catalog=sga2025-parent --wisesize --region=dr9-south --annotate --annotate-central-only --mp=32

  SGA2025-cutouts --outdir=/pscratch/sd/i/ioannis/SGA2025/wisesize --catalog=sga2025-parent --wisesize --region=dr9-north --annotated-montage
  SGA2025-cutouts --outdir=/pscratch/sd/i/ioannis/SGA2025/wisesize --catalog=sga2025-parent --wisesize --region=dr9-south --annotated-montage

LVD sample:
  SGA2025-cutouts --outdir=/pscratch/sd/i/ioannis/SGA2025/lvd --catalog=sga2025-parent --region=dr11-south --mp=32 --lvd
  SGA2025-cutouts --outdir=/pscratch/sd/i/ioannis/SGA2025/lvd --catalog=sga2025-parent --region=dr11-south --annotate --mp=32 --lvd
  SGA2025-cutouts --outdir=/pscratch/sd/i/ioannis/SGA2025/lvd --catalog=sga2025-parent --region=dr11-south --annotated-montage --lvd

zooniverse project:
  SGA2025-cutouts --outdir=/global/cfs/cdirs/cosmo/www/temp/SGA2025/zooniverse/project1 \
    --httpdir=https://portal.nersc.gov/project/cosmo/temp/SGA2025/zooniverse/project1 \
    --catalog=sga2025-parent --region=dr9-north --mp=32 --zooniverse
  SGA2025-cutouts --outdir=/global/cfs/cdirs/cosmo/www/temp/SGA2025/zooniverse/project1 \
    --httpdir=https://portal.nersc.gov/project/cosmo/temp/SGA2025/zooniverse/project1 \
    --catalog=sga2025-parent --region=dr9-north --mp=32 --zooniverse --annotate
  SGA2025-cutouts --outdir=/global/cfs/cdirs/cosmo/www/temp/SGA2025/zooniverse/project1 \
    --httpdir=https://portal.nersc.gov/project/cosmo/temp/SGA2025/zooniverse/project1 \
    --catalog=sga2025-parent --region=dr9-north --zooniverse --annotated-montage

"""
import pdb # for debugging

import os, re, sys, time
import numpy as np
import fitsio
from astropy.table import Table, vstack
import astropy.units as u
import multiprocessing

from astrometry.libkd.spherematch import match_radec
from astrometry.util.starutil_numpy import arcsec_between

import warnings
from astropy.io.fits.verify import VerifyWarning
warnings.simplefilter('ignore', category=VerifyWarning)

from SGA.io import sga_dir, custom_brickname, get_raslice, radec_to_name
from SGA.ellipse import choose_geometry, parse_geometry

GALEX_PIXSCALE = 1.5
UNWISE_PIXSCALE = 2.75


def photo_datamodel(out=None, bands=['g', 'r', 'i', 'z']):
    if out is None:
        out = Table()
    for col in ['RA', 'DEC']:
        for band in bands:
            out[f'{col}_PHOT_{band.upper()}'] = -99.
    for col in ['X', 'Y', 'DIAM', 'BA', 'PA']:
        for band in bands:
            out[f'{col}_PHOT_{band.upper()}'] = np.float32(-99.) # diam in arcsec
    for col in ['INIT', 'PHOT']:
        for band in bands:
            out[f'FLUX_{col}_{band.upper()}'] = np.float32(-99.)
    return out


def _photo_one(args):
    return photo_one(*args)


def photo_one(obj, outdir, bands=['g', 'r', 'i', 'z'], verbose=False):
    """Perform photometry on a single cutout.

    """
    from astropy.io import fits
    from astropy.wcs import WCS
    from astropy.wcs.utils import proj_plane_pixel_scales as get_pixscale
    from photutils.aperture import EllipticalAperture
    from photutils.morphology import data_properties
    from photutils.segmentation import SourceCatalog, SegmentationImage
    from SGA.qa import draw_ellipse
    from SGA.find_galaxy import find_galaxy
    import matplotlib.pyplot as plt


    ra, dec = obj['RA'], obj['DEC']

    objname = radec_to_name(ra, dec, unixsafe=True)[0]
    fitsfile = os.path.join(outdir, get_raslice(ra), objname+'.fits')
    if not os.path.isfile(fitsfile):
        print(f'Skipping missing file {fitsfile}')
        return Table()

    diam, ba, pa, ref = choose_geometry(Table(obj))
    out = Table(obj['OBJNAME', 'RA', 'DEC'])
    out['SGANAME'] = radec_to_name(ra, dec, unixsafe=False)[0]
    out['DIAM_INIT'] = diam[0].astype('f4')
    out['BA_INIT'] = ba[0].astype('f4')
    out['PA_INIT'] = pa[0].astype('f4')
    out = photo_datamodel(out, bands=bands)

    #img, hdr = fitsio.read(optfits, header=True)
    with fits.open(fitsfile) as H:
        if len(H) != 2:
            raise ValueError('Missing inverse variance extension!')
        hdr = H[0].header
        imgs = H[0].data
        ivars = H[1].data

    hdr['NAXIS'] = 2
    hdr.pop('NAXIS3')
    wcs = WCS(hdr, naxis=2)

    nband, width, _ = imgs.shape
    
    # FIXME - build the Gaia mask here
    #mask = np.zeros((width, width), bool)
    masks = ivars == 0

    pixscale = get_pixscale(wcs)[0] * 3600. # [arcsec/pixel]

    xinit, yinit = wcs.wcs_world2pix(ra, dec, 1)
    #xyinit = (xinit[0] - 1., yinit[0] - 1.)
    xyinit = (xinit, yinit)
    a_init = diam[0] / 2. / pixscale
    b_init = a_init * ba[0]
    theta_init = np.radians(90. - pa[0])

    ap_init = EllipticalAperture(
        xyinit, a=a_init, b=b_init, theta=theta_init)
    aps_phot = []

    for iband, band in enumerate(bands):
        img = imgs[iband, :, :]

        # no data
        if np.all(img == 0.):
            continue

        mask = masks[iband, :, :]
        error = ivars[iband, :, :]
        I = error != 0.
        error[I] = 1. / np.sqrt(error[I])

        # aperture photometry in initial ellipse
        flux_init, _ = ap_init.do_photometry(img, mask=mask)
        out[f'FLUX_INIT_{band.upper()}'] = flux_init[0]

        # now measure the geometry from the data themselves
        if False:
            src = data_properties(img, mask=mask)#, wcs=wcs)
            #src = SourceCatalog(img, SegmentationImage(np.ones_like(img, int)), error=error, mask=mask)[0]
            xyphot = (src.xcentroid, src.ycentroid)
            a_phot = 1.2 * src.semimajor_sigma.value
            b_phot = 1.2 * src.semiminor_sigma.value
            ba_phot = src.ellipticity.value
            pa_phot = 180. - src.orientation.value % 180.
            theta_phot = np.radians(src.orientation.value)
        else:        
            mge = find_galaxy(img, quiet=True)
            #plt.clf() ; mge = find_galaxy(img, quiet=True, plot=True) ; plt.savefig('ioannis/tmp/junk2.png')
            #pdb.set_trace()
            xyphot = (mge.ymed, mge.xmed) # swapped coordinates!
            a_phot = mge.majoraxis
            ba_phot = 1. - mge.eps
            b_phot = a_phot * ba_phot
            pa_phot = mge.pa
            theta_phot = np.radians(mge.theta)
        #pdb.set_trace()

        ap_phot = EllipticalAperture(xyphot, a=a_phot, b=b_phot, theta=theta_phot)
        flux_phot, _ = ap_phot.do_photometry(img)
        aps_phot.append(ap_phot)

        ra_phot, dec_phot = wcs.all_pix2world(xyphot[0], xyphot[1], 1)
        #sep = arcsec_between(ra, dec, ra_phot, dec_phot)

        out[f'RA_PHOT_{band.upper()}'] = ra_phot
        out[f'DEC_PHOT_{band.upper()}'] = dec_phot
        out[f'X_PHOT_{band.upper()}'] = xyphot[0]
        out[f'Y_PHOT_{band.upper()}'] = xyphot[1]
        out[f'DIAM_PHOT_{band.upper()}'] = 2. * a_phot * pixscale
        out[f'BA_PHOT_{band.upper()}'] = ba_phot
        out[f'PA_PHOT_{band.upper()}'] = pa_phot
        out[f'FLUX_PHOT_{band.upper()}'] = flux_phot[0]

    qaplot = True
    if qaplot:
        import matplotlib.pyplot as plt
        import matplotlib.image as mpimg
        
        jpgfile = os.path.join(outdir, get_raslice(ra), objname+'.jpeg')
        jpg = mpimg.imread(jpgfile)

        fig, ax = plt.subplots(figsize=(8, 8))
        #im = ax.imshow(jpg, origin='lower')
        #ax.invert_yaxis() # JPEG is flipped relative to FITS
        ax.imshow(np.log(img), origin='lower', cmap='viridis')
        ax.set_xlim(0, width)
        ax.set_ylim(0, width)
        #ax.axis('off')
        #ax.axhline(y=width/2., color='white')
        #ax.axvline(x=width/2., color='white')
        ap_init.plot(color='red', ls='-', lw=2, ax=ax)
        draw_ellipse(ax, diam[0], ba[0], pa[0], xinit, width-yinit, pixscale=pixscale, 
                     color='orange', linestyle='-', majorminor=True)
        #for ap_phot in aps_phot:
        #    ap_phot.plot(color='red', ls='-', lw=2, ax=ax)
        for iband, band in enumerate(bands):
            draw_ellipse(ax, out[f'DIAM_PHOT_{band.upper()}'], out[f'BA_PHOT_{band.upper()}'], 
                         out[f'PA_PHOT_{band.upper()}'], out[f'X_PHOT_{band.upper()}'], 
                         out[f'Y_PHOT_{band.upper()}'], pixscale=pixscale, 
                         color='blue', linestyle='--', majorminor=True)

        #_ = src.plot_kron_apertures(ax=ax[iband], color='white', lw=1.5)

        fig.tight_layout()
        fig.savefig('ioannis/tmp/junk.png')

    print(out.pprint(max_width=-1))
    pdb.set_trace()

    return


def do_photo(cat, comm=None, mp=1, indir='.', bands=['g', 'r', 'i', 'z'],
             region='dr9-north', outdir='.', overwrite=False, dry_run=False, 
             verbose=False):

    """Wrapper to set up the full set of annotations.

    """
    if comm is None:
        rank, size = 0, 1
    else:
        rank, size = comm.rank, comm.size

    if rank == 0:
        t0 = time.time()
        groups = np.array_split(range(len(cat)), size) # unweighted distribution
    else:
        groups = [np.array([])]

    if comm:
        groups = comm.bcast(groups, root=0)

    assert(len(groups) == size)

    indx = groups[rank]
    if len(indx) == 0:
        return

    mpargs = [(cat[indx[iobj]], outdir, bands) for iobj in range(len(indx))]
    if mp > 1:
        with multiprocessing.Pool(mp) as P:
            P.map(_photo_one, mpargs)
    else:
        [photo_one(*mparg) for mparg in mpargs]

    sys.stdout.flush()

    if comm is not None:
        comm.barrier()

    if rank == 0 and not dry_run:
        print(f'All done at {time.asctime()}')


def sandbox_photo(cat, comm=None, indir='.', region='dr9-north',
                  outdir='.', overwrite=False, dry_run=False, 
                  verbose=False):
    pdb.set_trace()
    # https://photutils.readthedocs.io/en/stable/user_guide/segmentation.html
    from photutils.morphology import data_properties
    from photutils.background import Background2D, MedianBackground
    from photutils.segmentation import detect_sources, deblend_sources, SourceCatalog

    import matplotlib.pyplot as plt
    from astropy.visualization import SqrtStretch
    from astropy.visualization.mpl_normalize import ImageNormalize

    # read the WCS and image cutouts
    data = img[1, :, :]
    bkg = Background2D(data, (50, 50), filter_size=(3, 3),
                       bkg_estimator=MedianBackground)
    thresh = 2.5 * bkg.background_rms
    seg = detect_sources(data, thresh, npixels=10)

    dseg = deblend_sources(data, seg, npixels=30, nlevels=8, contrast=0.1, progress_bar=True)
    srcs = SourceCatalog(data, dseg, convolved_data=data)

    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 12.5))
    ax1.imshow(data, origin='lower', cmap='Greys_r', norm=ImageNormalize(stretch=SqrtStretch()))
    ax2.imshow(dseg, origin='lower', cmap=dseg.cmap, interpolation='nearest')
    _ = srcs.plot_kron_apertures(ax=ax1, color='white', lw=1.5)
    _ = srcs.plot_kron_apertures(ax=ax2, color='white', lw=1.5)
    fig.savefig('ioannis/tmp/junk.png')





def _get_annotate_one(args):
    return get_annotate_one(*args)


def get_annotate_one(obj, objname, indir, outdir, overwrite=False, verbose=False):
    raslice = get_raslice(obj['RA'])

    if objname is None:
        brick = custom_brickname(obj['RA'], obj['DEC'])
        jpgfile = os.path.join(indir, raslice, brick[:6], f'{brick}.jpeg')
        pngfile = os.path.join(outdir, raslice, brick[:6], f'{brick}.png')
    else:
        jpgfile = os.path.join(indir, raslice, f'{objname}.jpeg')
        pngfile = os.path.join(outdir, raslice, f'{objname}.png')
    nobj = 1

    if overwrite is False:
        if os.path.isfile(pngfile):
            nobj = 0
            if verbose:
                print(f'Skipping existing annotated cutout {pngfile}')
    else:
        if not os.path.isfile(jpgfile):
            nobj = 0
            print(f'Missing input cutout {jpgfile}')

    return jpgfile, pngfile, nobj


def get_wcs(racenter, deccenter, width, pixscale=0.262):
    from astropy.wcs import WCS
    from astropy.io import fits
    hdr = fits.Header()
    hdr['NAXIS'] = 2
    hdr['NAXIS1'] = width
    hdr['NAXIS2'] = width
    hdr['CTYPE1'] = 'RA---TAN'
    hdr['CTYPE2'] = 'DEC--TAN'
    hdr['CRVAL1'] = racenter
    hdr['CRVAL2'] = deccenter
    hdr['CRPIX1'] = width/2+0.5
    hdr['CRPIX2'] = width/2+0.5
    hdr['CD1_1'] = -pixscale/3600.
    hdr['CD1_2'] = 0.0
    hdr['CD2_1'] = 0.0
    hdr['CD2_2'] = +pixscale/3600.
    return WCS(hdr)


def _annotate_one(args):
    return annotate_one(*args)


def annotate_one(jpgfile, pngfile, objname, commonname, pixscale,
                 mosaic_diam, draw_largest_ellipse, primary, group):
    """Annotate one image.

    """
    import matplotlib.pyplot as plt
    import matplotlib.image as mpimg
    from astropy.wcs import WCS
    from astropy.io import fits
    from SGA.qa import draw_ellipse


    if not os.path.isfile(jpgfile):
        return

    bbox = dict(boxstyle='round', facecolor='k', alpha=0.5)
    ref_pixscale = 0.262
    barlen = 15 / pixscale # [pixels]
    barlabel = '15 arcsec'

    N = len(group)
    primary_ra, primary_dec = primary['RA'], primary['DEC']
    row_parent = primary['ROW_PARENT']

    img = mpimg.imread(jpgfile)
    width = img.shape[0]
    wcs = get_wcs(primary_ra, primary_dec, width, pixscale=pixscale)

    ellipse_colors = {'RC3': 'yellow', 'SMUDGes': 'orange', 'LVD': 'violet', 
                      'SGA2020': 'dodgerblue', 'HYPERLEDA': 'red', 
                      'ESO': 'pink', 'SDSS': 'pink', 'TWOMASS': 'pink', 
                      'BASIC': 'pink', 'LIT': 'pink', 'CUSTOM': 'pink', 
                      'NONE': 'pink', '': 'pink'}
    ellipse_linestyles = {'RC3': 'solid', 'SMUDGes': 'solid', 'LVD': 'solid',
                          'SGA2020': 'dashed', 'HYPERLEDA': 'dashdot',
                          'ESO': 'dashed', 'SDSS': 'dashed', 'TWOMASS': 'dashed',
                          'BASIC': 'dashed', 'LIT': 'dashed', 'CUSTOM': 'dashed', 
                          'NONE': 'dashed', '': 'dashed'}

    outdir = os.path.dirname(pngfile)
    if not os.path.isdir(outdir):
        os.makedirs(outdir, exist_ok=True)
    #pngfile = '/global/homes/i/ioannis/ioannis/tmp/'+os.path.basename(pngfile)

    fig, ax = plt.subplots(figsize=(8, 8))
    im = ax.imshow(img, origin='lower')
    ax.set_xlim(0, width)
    ax.set_ylim(0, width)

    # only keep objects in the image
    keep = np.ones(len(group), bool)
    for imem, onegal in enumerate(group):
        xpix, ypix = wcs.wcs_world2pix(onegal['RA'], onegal['DEC'], 1)
        if xpix < 0 or ypix < 0 or xpix > width or ypix > width:
            keep[imem] = False
    group = group[keep]

    #print('HACK!!!')
    #if len(group) > 500:
    if len(group) > 10:
        print('WARNING: Too many group members; keeping just the 10 largest objects!')
        # group includes primary, so we need to be sure it doesn't get removed
        group_noprimary = group.copy()
        group_noprimary.remove_row(np.where(primary['ROW_PARENT'] == group['ROW_PARENT'])[0][0])
        # set mindiam=0 to prioritize existing diameter estimates
        diam, _, _, _ = choose_geometry(group_noprimary, mindiam=0.)
        srt = np.argsort(diam)[::-1]
        group_noprimary = group_noprimary[srt[:10]]
        group = vstack((Table(primary), group_noprimary))
        del group_noprimary

    objnames, xpixes, ypixes = [], [], []
    for imem, onegal in enumerate(group):
        ra = onegal['RA']
        dec = onegal['DEC']
        xpix, ypix = wcs.wcs_world2pix(ra, dec, 1)
        #if xpix < 0 or ypix < 0 or xpix > width or ypix > width:
        #    continue

        if onegal['OBJNAME'] != primary['OBJNAME']:
            objnames.append(onegal['OBJNAME'])
            xpixes.append(xpix)
            ypixes.append(ypix)

        if draw_largest_ellipse:
            diam, ba, pa, ref = choose_geometry(Table(onegal))
            diam = diam[0]
            ba = ba[0]
            pa = pa[0]
            ref = ref[0]
            if diam > 0.:
                if onegal['OBJNAME'] == primary['OBJNAME']:
                    majorminor = True
                else:
                    majorminor = False
                draw_ellipse(ax, diam, ba, pa, xpix, width-ypix, pixscale=pixscale, color=ellipse_colors[ref],
                             linestyle=ellipse_linestyles[ref], majorminor=majorminor)
        else:
            for ref in ['SGA2020', 'HYPERLEDA', 'LIT']:
                diam, ba, pa, outref = parse_geometry(Table(onegal), ref)
                #print(onegal['OBJNAME'], outref, diam, ellipse_colors[outref])
                if diam > 0.:
                    #print(onegal['OBJNAME'], ref, xpix, ypix, diam[0], ba[0], pa[0])
                    if onegal['OBJNAME'] == primary['OBJNAME']:
                        majorminor = True
                    else:
                        majorminor = False
                    draw_ellipse(ax, diam, ba, pa, xpix, width-ypix, pixscale=pixscale, color=ellipse_colors[outref],
                                 linestyle=ellipse_linestyles[outref], majorminor=majorminor)

    # now annotate
    if len(objnames) > 0:
        def label_neighbor(objname, xy, xyname, xytext, ha='center', va='top'):
            ax.annotate('', xy=xy, xytext=xytext, annotation_clip=True, 
                        arrowprops={'arrowstyle': '-', 'color': 'white'})
                        #dict(facecolor='white', edgecolor='white', width=0.5,
                        #     headwidth=2, shrink=0.005, alpha=0.75))
            ax.annotate(objname, xy=xyname, xytext=xytext, va=va, ha=ha,
                        color='white', bbox=bbox, fontsize=9,
                        annotation_clip=True)

        objnames = np.array(objnames)
        xpixes = np.array(xpixes)
        ypixes = np.array(ypixes)

        ysrt = np.argsort(ypixes)
        objnames = objnames[ysrt]
        xpixes = xpixes[ysrt]
        ypixes = ypixes[ysrt]

        lhs = xpixes < width / 2
        rhs = xpixes >= width / 2
        Nlhs = np.sum(lhs)
        Nrhs = np.sum(rhs)

        xmargin = 0.15 * width
        ymargin = 0.1 * width # 10% pixel margin
        if Nlhs > 0:
            lhs_yoffset = np.linspace(ymargin*2, width-ymargin*2, Nlhs)
            lhs_xoffset = xmargin + 0.1 * width * np.sin(np.linspace(0, 2*np.pi, Nlhs))
            for objname, xpix, ypix, xoffset, yoffset in zip(
                    objnames[lhs], xpixes[lhs], ypixes[lhs], lhs_xoffset, lhs_yoffset):
                xy = (xpix, width-ypix)
                xyname = (xoffset, width-yoffset)
                xytext = (xoffset, width-yoffset)
                #print(objname, xy, xyname, xytext)
                label_neighbor(objname, xy, xyname, xytext, ha='center', va='top')
        if Nrhs > 0:
            rhs_yoffset = np.linspace(ymargin*3, width-ymargin*2, Nrhs)
            rhs_xoffset = width - (xmargin + 0.1 * width * np.sin(np.linspace(0, 2*np.pi, Nrhs)))
            for objname, xpix, ypix, xoffset, yoffset in zip(
                    objnames[rhs], xpixes[rhs], ypixes[rhs], rhs_xoffset, rhs_yoffset):
                xy = (xpix, width-ypix)
                yname = width - yoffset
                # shift the position if the label is too close to the object
                if (yoffset - ypix) / width < 0.1:
                    yname /= 1.1
                elif (ypix - yoffset) / width < 0.1:
                    yname *= 1.1
                xyname = (xoffset, yname)
                xytext = (xoffset, yname)
                #print(objname, xy, xyname, xytext)
                label_neighbor(objname, xy, xyname, xytext, ha='center', va='top')

    ax.invert_yaxis() # JPEG is flipped relative to my FITS WCS
    ax.axis('off')
    if primary['MORPH'].strip() == '':
        morph = primary["OBJTYPE"].strip()
    else:
        morph = primary["OBJTYPE"].strip() +'; '+re.sub(r'\s+', ' ', primary["MORPH"])

    txt = '\n'.join([commonname, #objname.replace('_', ' '),
                     morph, f'{primary_ra:.7f}, {primary_dec:.6f}'])
                     #r'$(\alpha,\delta)$='+f'({primary_ra:.7f}, {primary_dec:.6f})'])
    #txt = '\n'.join([commonname+f' {morph}', objname.replace('_', ' '),
    #                 r'$(\alpha,\delta)$='+f'({primary_ra:.7f}, {primary_dec:.6f})'])
    ax.text(0.03, 0.93, txt, transform=ax.transAxes, ha='left', va='center',
            color='white', bbox=bbox, linespacing=1.5, fontsize=10)

    # add the scale bar
    xpos, ypos = 0.07, 0.07
    dx = barlen / img.shape[0]
    ax.plot([xpos, xpos+dx], [ypos, ypos], transform=ax.transAxes,
            color='white', lw=2)
    ax.text(xpos + dx/2., ypos+0.02, barlabel, transform=ax.transAxes,
            ha='center', va='center', color='white')
    ax.text(1-xpos, ypos, str(row_parent), transform=ax.transAxes,
            ha='right', va='center', color='white')

    fig.tight_layout()
    fig.savefig(pngfile, bbox_inches=0)#, dpi=200)
    plt.close()
    print(f'Wrote {pngfile}')


def do_annotate(cat, fullcat=None, default_width=152, default_pixscale=0.262,
                comm=None, mp=1, indir='.', outdir='.', base_outdir='.', 
                region='dr9-north', fits_cutouts=True, draw_largest_ellipse=False, 
                httpdir=None, overwrite=False, debug=False, annotate_central_only=False, 
                dry_run=False, verbose=False):
    """Wrapper to set up the full set of annotations.

    """
    if comm is None:
        rank, size = 0, 1
    else:
        rank, size = comm.rank, comm.size

    t0 = time.time()
    if rank == 0:
        mindiam = default_width * default_pixscale # [arcsec]
        diam, ba, pa, ref = choose_geometry(cat, mindiam=mindiam)
    
        pixscale, width = get_pixscale_and_width(
            diam, mindiam, rescale=False,
            default_width=default_width,
            default_pixscale=default_pixscale)

        jpgfiles, pngfiles, groups = plan(
            cat, size=size, outdir=outdir, 
            indir=indir, overwrite=overwrite, mp=mp, 
            fits_cutouts=fits_cutouts,
            verbose=verbose, annotate=True)
        print(f'Planning took {time.time() - t0:.2f} sec')

        # write out an inventory file
        if httpdir:
            objnames = radec_to_name(cat['RA'].value, cat['DEC'].value, unixsafe=True)
            inventoryfile = os.path.join(base_outdir, f'inventory-{region}.txt')
            with open(inventoryfile, 'w') as F:
                for objname, pngfile in zip(objnames, pngfiles):
                    F.write(f'{pngfile.replace(base_outdir, httpdir)},{objname}\n')
            print(f'Wrote {inventoryfile}')

    else:
        jpgfiles, pngfiles, groups = [], [], []
        pixscale, diam = [], []

    if comm:
        jpgfiles = comm.bcast(jpgfiles, root=0)
        pngfiles = comm.bcast(pngfiles, root=0)
        groups = comm.bcast(groups, root=0)
        pixscale = comm.bcast(pixscale, root=0)
        diam = comm.bcast(diam, root=0)
    sys.stdout.flush()

    # all done
    if len(jpgfiles) == 0 or len(np.hstack(jpgfiles)) == 0:
        return
        
    assert(len(groups) == size)

    print(f'Rank {rank} started at {time.asctime()}')
    sys.stdout.flush()

    indx = groups[rank]
    if len(indx) == 0:
        return

    commonname = cat['OBJNAME'][indx].value
    objname = radec_to_name(cat['RA'][indx].value, cat['DEC'][indx].value, unixsafe=True)

    # initial match
    allmatches = match_radec(cat['RA'][indx].value, cat['DEC'][indx].value,
                             fullcat['RA'].value, fullcat['DEC'].value,
                             2.*np.max(diam)/3600., indexlist=True, notself=False)
    
    mpargs = []
    for iobj in range(len(indx)):
        #print(iobj)
        primary = cat[indx[iobj]]
        if annotate_central_only:
            group = Table(primary)
        else:
            # refine the search to this object's diameter
            m1, m2, _ = match_radec(primary['RA'], primary['DEC'], fullcat['RA'][allmatches[iobj]],
                                    fullcat['DEC'][allmatches[iobj]], 2.*diam[indx[iobj]]/3600.)
            group = fullcat[allmatches[iobj]][m2]
        if debug:
            print(primary['OBJNAME'])
            for one in group:
                if one['OBJNAME'] != primary['OBJNAME']:
                    print(one['OBJNAME'])
            print()
        else:
            mpargs.append((jpgfiles[iobj], pngfiles[iobj], objname[iobj], commonname[iobj],
                           pixscale[indx[iobj]], diam[indx[iobj]], draw_largest_ellipse,
                           primary, group))

    if debug:
        return

    if mp > 1:
        with multiprocessing.Pool(mp) as P:
            P.map(_annotate_one, mpargs)
    else:
        [annotate_one(*mparg) for mparg in mpargs]

    #print(f'  rank {rank} is done')
    sys.stdout.flush()

    if comm is not None:
        comm.barrier()

    if rank == 0 and not dry_run:
        print(f'All done at {time.asctime()}')
    

def _cutout_one(args):
    return cutout_one(*args)


def cutout_one(basefile, ra, dec, optical_width, optical_pixscale, 
               optical_layer, optical_bands, dry_run, fits_cutouts, 
               ivar_cutouts, unwise_cutouts, galex_cutouts, rank, iobj):
    """
    pixscale = 0.262
    width = int(30 / pixscale)   # =114
    height = int(width / 1.3) # =87 [3:2 aspect ratio]

    shifterimg pull dstndstn/viewer-cutouts:latest
    shifter --image dstndstn/viewer-cutouts cutout --output cutout.jpg --ra 234.2915 --dec 16.7684 --size 256 --layer ls-dr9 --pixscale 0.262 --force

    TODO - handle the invvar images

    """
    from cutout import cutout

    suffixes = ['.jpeg', ]
    layers = [optical_layer, ]
    pixscales = [optical_pixscale, ]
    widths = [optical_width, ]
    allbands = [optical_bands, ]

    if fits_cutouts:
        suffixes += ['.fits', ]
        layers += [optical_layer, ]
        pixscales += [optical_pixscale, ]
        widths += [optical_width, ]
        allbands += [optical_bands, ]
    if unwise_cutouts:
        unwise_width = int(optical_width * optical_pixscale / UNWISE_PIXSCALE)
        unwise_suffixes = ['-W1W2.fits', '-W3W4.fits', ]
        suffixes += unwise_suffixes
        layers += ['unwise-neo7', 'unwise-w3w4', ]
        pixscales += [UNWISE_PIXSCALE, UNWISE_PIXSCALE, ]
        widths += [unwise_width, unwise_width, ]
        allbands += [['1', '2'], ['3', '4'], ]
    if galex_cutouts:
        galex_width = int(optical_width * optical_pixscale / GALEX_PIXSCALE)
        suffixes += ['-galex.fits', ]
        layers += ['galex', ]
        pixscales += [GALEX_PIXSCALE, ]
        widths += [galex_width, ]
        allbands += [['f', 'n'], ]
    
    for suffix, layer, pixscale, width, bands in zip(suffixes, layers, pixscales, widths, allbands):
        outfile = basefile+suffix
        cmdargs = f'--output={outfile} --ra={ra} --dec={dec} --size={width} ' + \
            f'--layer={layer} --pixscale={pixscale} --bands={",".join(bands)} --force'
        if suffix != '.jpeg' and ivar_cutouts:
            cmdargs += ' --invvar'

        if dry_run:
            if suffix == '.jpeg':
                print(f'Rank {rank}, object {iobj}: cutout {cmdargs}')
        else:
            if suffix == '.jpeg':
                outdir = os.path.dirname(basefile)
                if not os.path.isdir(outdir):
                    os.makedirs(outdir, exist_ok=True)
            try:
                cutout(ra, dec, outfile, size=width, layer=layer, pixscale=pixscale, 
                       invvar=ivar_cutouts, bands=bands, force=True)
                #if suffix == '.jpeg':
                #    print(f'Rank {rank}, object {iobj}: cutout {cmdargs}')
                print(f'Rank {rank}, object {iobj}: cutout {cmdargs}')
            except:
                if suffix == '.jpeg':
                    print(f'WARNING: Rank {rank}, object {iobj} off the footprint: cutout {cmdargs}')                

    # merge the W1W2 and W3W4 files
    if unwise_cutouts:
        for ii, suffix in enumerate(unwise_suffixes):
            infile = basefile+suffix
            if ii == 0:
                hdr = fitsio.read_header(infile)
                for key in ['BANDS', 'BAND0', 'BAND1', 'COMMENT']:
                    hdr.delete(key)
                hdr['BANDS'] = '1234'
                for band in range(4):
                    hdr[f'BAND{band}'] = str(band+1)
                hdr['NAXIS3'] = 4
                #hdr['EXTNAME'] = 'IMAGE'
                img = np.zeros((4, hdr['NAXIS2'], hdr['NAXIS1']), 'f4')
                img[:2, :, :] = fitsio.read(infile, ext=0)
                if ivar_cutouts:
                    hdr_ivar = fitsio.read_header(infile, ext=1)
                    for key in ['BANDS', 'BAND0', 'BAND1']:
                        hdr_ivar.delete(key)
                    hdr_ivar['BANDS'] = '1234'
                    for band in range(4):
                        hdr_ivar[f'BAND{band}'] = str(band+1)
                    hdr_ivar['NAXIS3'] = 4
                    #hdr_ivar['EXTNAME'] = 'INVVAR'
                    ivar = np.zeros_like(img)
                    ivar[:2, :, :] = fitsio.read(infile, ext=1)
            else:
                img[2:, :, :] = fitsio.read(infile, ext=0)
                if ivar_cutouts:
                    ivar[2:, :, :] = fitsio.read(infile, ext=1)
            os.remove(infile)
        outfile = basefile+'-unwise.fits'
        fitsio.write(outfile, img, header=hdr, clobber=True)
        if ivar_cutouts:
            fitsio.write(outfile, ivar, header=hdr_ivar)


def _get_basefiles_one(args):
    return get_basefiles_one(*args)


def get_basefiles_one(obj, objname, outdir, width=None, fits_cutouts=True, 
                      unwise_cutouts=False, galex_cutouts=False,
                      overwrite=False, verbose=False):
    raslice = get_raslice(obj['RA'])

    if objname is None:
        brick = custom_brickname(obj['RA'], obj['DEC'])
        basefile = os.path.join(outdir, raslice, brick[:6], brick)
    else:
        basefile = os.path.join(outdir, raslice, objname)
    nobj = 1

    jpeg = os.path.isfile(basefile+'.jpeg')

    if overwrite is False:
        if fits_cutouts:
            fits = os.path.isfile(basefile+'.fits')
        else:
            fits = True
        if unwise_cutouts:
            unwise = os.path.isfile(basefile+'-unwise.fits')
        else:
            unwise = True
        if galex_cutouts:
            galex = os.path.isfile(basefile+'-galex.fits')
        else:
            galex = True

        if jpeg and fits and unwise and galex:
            # need to make sure the image is the correct size
            #width_exist = int(fitsio.read_header(basefile+'.fits')['IMAGEW'])
            #if width == width_exist:
            nobj = 0
            if verbose:
                print(f'Skipping existing cutout {basefile}.')

    return basefile, obj['RA'], obj['DEC'], nobj


def plan(cat, width=152, layer='ls-dr9', indir='.', outdir='.',
         size=1, mp=1, photo=False, annotate=False, fits_cutouts=True,
         unwise_cutouts=False, galex_cutouts=False, overwrite=False,
         verbose=False):
    """Build a plan!

    """
    t0 = time.time()

    objname = radec_to_name(cat['RA'], cat['DEC'], unixsafe=True)

    if annotate:
        mpargs = [(obj, objname1, indir, outdir, overwrite, verbose) 
                  for obj, objname1 in zip(cat, objname)]
        if mp > 1:
            with multiprocessing.Pool(mp) as P:
                out = P.map(_get_annotate_one, mpargs)
        else:
            out = [get_annotate_one(*mparg) for mparg in mpargs]
        out = list(zip(*out))
    
        jpgfiles = np.array(out[0], dtype=object)
        pngfiles = np.array(out[1], dtype=object)
        nobj = np.array(out[2], dtype=object)
    else:
        if np.isscalar(width):
            width = [width] * len(objname)

        mpargs = [(obj, objname1, outdir, width1, fits_cutouts, unwise_cutouts, 
                   galex_cutouts, overwrite, verbose)
                  for obj, objname1, width1 in zip(cat, objname, width)]
        if mp > 1:
            with multiprocessing.Pool(mp) as P:
                out = P.map(_get_basefiles_one, mpargs)
        else:
            out = [get_basefiles_one(*mparg) for mparg in mpargs]
        out = list(zip(*out))
    
        basefiles = np.array(out[0], dtype=object)
        allra = np.array(out[1], dtype=object)
        alldec = np.array(out[2], dtype=object)
        nobj = np.array(out[3], dtype=object)

    iempty = np.where(nobj == 0)[0]
    if len(iempty) > 0:
        if annotate:
            print(f'Skipping {len(iempty):,d} objects with existing annotated images.')
        else:
            print(f'Skipping {len(iempty):,d} objects with existing cutouts.')

    itodo = np.where(nobj > 0)[0]
    if len(itodo) > 0:
        nobj = nobj[itodo]
        if annotate:
            print(f'Annotated images needed for {np.sum(nobj):,d} objects.')
            jpgfiles = jpgfiles[itodo]
            pngfiles = pngfiles[itodo]
        else:
            print(f'Cutouts needed for {np.sum(nobj):,d} objects.')
            basefiles = basefiles[itodo]
            allra = allra[itodo]
            alldec = alldec[itodo]
        groups = np.array_split(itodo, size) # unweighted distribution
    else:
        groups = [np.array([])]

    if annotate:
        return jpgfiles, pngfiles, groups
    else:
        return basefiles, allra, alldec, groups


def do_cutouts(cat, layer='ls-dr9', default_width=152, default_pixscale=0.262,
               default_bands=['g', 'r', 'i', 'z'], comm=None, mp=1, outdir='.',
               base_outdir='.', rescale=False, overwrite=False, fits_cutouts=True,
               ivar_cutouts=False, unwise_cutouts=False, galex_cutouts=False,
               dry_run=False, verbose=False):

    if comm is None:
        rank, size = 0, 1
    else:
        rank, size = comm.rank, comm.size

    t0 = time.time()
    if rank == 0:
        mindiam = default_width * default_pixscale # [arcsec]
        diam, ba, pa, ref = choose_geometry(cat, mindiam=mindiam)
    
        pixscale, width = get_pixscale_and_width(
            diam, mindiam, rescale=rescale, 
            default_width=default_width,
            default_pixscale=default_pixscale)
    
        basefiles, allra, alldec, groups = plan(
            cat, width=width, layer=layer, outdir=outdir, 
            size=size, overwrite=overwrite, mp=mp, 
            fits_cutouts=fits_cutouts, unwise_cutouts=unwise_cutouts,
            galex_cutouts=galex_cutouts, verbose=verbose)
        print(f'Planning took {time.time() - t0:.2f} sec')
    else:
        basefiles, allra, alldec, groups = [], [], [], []
        pixscale, width = [], []

    if comm:
        basefiles = comm.bcast(basefiles, root=0)
        allra = comm.bcast(allra, root=0)
        alldec = comm.bcast(alldec, root=0)
        groups = comm.bcast(groups, root=0)
        pixscale = comm.bcast(pixscale, root=0)
        width = comm.bcast(width, root=0)
    sys.stdout.flush()
    
    # all done
    if len(basefiles) == 0 or len(np.hstack(basefiles)) == 0:
        return
        
    assert(len(groups) == size)

    print(f'Rank {rank} started at {time.asctime()}')
    sys.stdout.flush()

    indx = groups[rank]
    if len(indx) == 0:
        return

    mpargs = [(basefiles[iobj], allra[iobj], alldec[iobj], width[indx[iobj]],
               pixscale[indx[iobj]], layer, default_bands, dry_run, 
               fits_cutouts, ivar_cutouts, unwise_cutouts, galex_cutouts, 
               rank, iobj) for iobj in range(len(indx))]
    if mp > 1:
        with multiprocessing.Pool(mp) as P:
            P.map(_cutout_one, mpargs)
    else:
        [cutout_one(*mparg) for mparg in mpargs]

    sys.stdout.flush()

    if comm is not None:
        comm.barrier()

    if rank == 0 and not dry_run:
        print(f'All done at {time.asctime()}')


def get_pixscale_and_width(diam, mindiam, rescale=False, maxdiam_arcmin=25.,
                           default_width=152, default_pixscale=0.262):
    """Simple function to compute the pixel scale of the desired
    output images.

    """
    nobj = len(diam)

    if rescale:
        # scale the pixel scale so that larger objects "fit" in DEFAULT_WIDTH
        pixscale = default_pixscale * 1.5 * diam / mindiam   # [arcsec/pixel]
        width = np.zeros(nobj, int) + default_width # [pixels]
    else:
        # full-mosaic, native resolution width, except for objects
        # larger than XX arcmin
        pixscale = np.zeros(nobj) + default_pixscale # [arcsec/pixel]
        width = 1.5 * diam / pixscale # [pixels]
    
        maxdiam = maxdiam_arcmin * 60. # [arcsec]
        I = diam > maxdiam
        if np.any(I):
            pixscale[I] = default_pixscale * diam[I] / maxdiam
            width[I] = 1.5 * diam[I] / pixscale[I]
    
    width = width.astype(int)

    return pixscale, width


def build_ssl_legacysurvey_refcat(cat, fullcat, ssl_version=None):
    """Build the reference catalog for use with ssl-legacysurvey

    v1 - original dr9-north and dr9-south version; mindiam = 10.
    v2 - like v1 but with mindiam = 30. (but did not perform well)
    v3 - like v1 but with dr9-north and dr11-south

    """
    def find_isolated(cat, fullcat, radius=90.):
        """Identify isolated sources.

        radius in arcsec

        """
        allmatches = match_radec(cat['RA'].value, cat['DEC'].value,
                                 fullcat['RA'].value, fullcat['DEC'].value,
                                 radius/3600., indexlist=True, notself=False)
        refindx = []
        for ii, mm in enumerate(allmatches):
            if len(mm) == 1:
                refindx.append(ii)
        refindx = np.array(refindx)
        return refindx


    # define the reference sample
    diam, _, _, ref = choose_geometry(cat, mindiam=0.)

    if ssl_version == 'v1':
        I = np.where((diam/60. > 1.5) * (diam/60. < 5.) * ~cat['RESOLVED'] * 
                     (cat['STARFDIST'] > 1.5) * (cat['FILTERS'] == 'grz'))[0]
        # no other source (of any size) within 90 arcsec
        refindx = find_isolated(cat[I], fullcat, radius=90.)
        refcat = cat[I[refindx]]
    elif ssl_version == 'v2':
        I = np.where((diam/60. > 1.7) * (diam/60. < 5.) * ~cat['RESOLVED'] * 
                     (cat['STARFDIST'] > 1.5) * (cat['FILTERS'] == 'grz'))[0]
        diam_full, _, _, _ = choose_geometry(fullcat, mindiam=0.)
        J = (diam_full > 30.) * (fullcat['FILTERS'] == 'grz')
        # no other source smaller than 30 arcsec within 90 arcsec
        refindx = find_isolated(cat[I], fullcat[J], radius=90.)
        refcat = cat[I[refindx]]
    elif ssl_version == 'v3':
        I = np.where((diam/60. > 1.7) * (diam/60. < 5.) * ~cat['RESOLVED'] * 
                     (cat['STARFDIST'] > 1.5) * 
                     np.logical_or(cat['FILTERS'] == 'grz', cat['FILTERS'] == 'girz'))[0]
        diam_full, _, _, _ = choose_geometry(fullcat, mindiam=0.)
        J = (diam_full > 30.) * np.logical_or(fullcat['FILTERS'] == 'grz', fullcat['FILTERS'] == 'girz')
        # no other source smaller than 30 arcsec within 90 arcsec
        refindx = find_isolated(cat[I], fullcat[J], radius=90.)
        refcat = cat[I[refindx]]
    elif ssl_version == 'v4':
        pdb.set_trace()

    else:
        raise ValueError('Write me')

    #sslcols = ['OBJNAME', 'RA', 'DEC', 'FILTERS', 'ROW_PARENT', 'REGION']
    #refcat = refcat[sslcols]

    if ssl_version == 'v1':
        mindiam = 10.
        print('Trimming the ssl_legacysurvey sample to unresolved objects ' + \
              f'smaller than {mindiam:.0f} arcsec.')
        I = (diam < mindiam) * (cat['FILTERS'] == 'grz') * ~cat['RESOLVED']
        cat = cat[I]
    elif ssl_version == 'v2':
        mindiam = 30.
        print('Trimming the ssl_legacysurvey sample to unresolved objects ' + \
              f'smaller than {mindiam:.0f} arcsec.')
        I = (diam < mindiam) * (cat['FILTERS'] == 'grz') * ~cat['RESOLVED']
        cat = cat[I]
    elif ssl_version == 'v3':
        mindiam = 10.
        print('Trimming the ssl_legacysurvey sample to unresolved objects ' + \
              f'smaller than {mindiam:.0f} arcsec.')
        I = (diam < mindiam) * np.logical_or(cat['FILTERS'] == 'grz', cat['FILTERS'] == 'girz') * ~cat['RESOLVED']
        cat = cat[I]
    else:
        raise ValueError('Write me')

    return refcat, cat


def build_ssl_legacysurvey(cat, fullcat, width=152, ncatmax=15000, ssl_version=None,
                           bands=['g', 'r', 'z'], outdir='.', verbose=False, 
                           overwrite=False):
    """Build the hdf5 file needed by ssl-legacysurvey.

    nband = 3 (grz)
    ncatmax - maximum number of files per output catalog

    """
    import h5py

    def get_fitsfiles(cat, region):
        cutoutdir = os.path.join(outdir, region, 'rescale')
        I = []
        fitsfiles = []
        for ii, one in enumerate(cat):
            objname = radec_to_name(one['RA'], one['DEC'])[0].replace(' ', '_')
            fitsfile = os.path.join(cutoutdir, get_raslice(one['RA']), f'{objname}.fits')
            if os.path.isfile(fitsfile):
                I.append(ii)
                fitsfiles.append(fitsfile)
            else:
                print(f'Missing {fitsfile}')

        return np.array(fitsfiles), np.array(I)

    nband = len(bands)

    if ssl_version is None:
        print('ssl_version must be specified')
        return

    # need to define a reference sample and make sure the files exist
    refcat, cat = build_ssl_legacysurvey_refcat(cat, fullcat, ssl_version=ssl_version)
    pdb.set_trace()

    refcatfiles, refcatindx = [], []
    catfiles, catindx = [], []
    for region in sorted(set(refcat['REGION'])):
        R = np.where(refcat['REGION'] == region)[0]
        C = np.where(cat['REGION'] == region)[0]
        refcatfiles1, refcatindx1 = get_fitsfiles(refcat[R], region)
        catfiles1, catindx1 = get_fitsfiles(cat[C], region)
        refcatfiles.append(refcatfiles1)
        catfiles.append(catfiles1)
        refcatindx.append(R[refcatindx1])
        catindx.append(C[catindx1])

    refcatfiles = np.hstack(refcatfiles)
    catfiles = np.hstack(catfiles)
    refcatindx = np.hstack(refcatindx)
    catindx = np.hstack(catindx)

    cat = cat[catindx]
    refcat = refcat[refcatindx]
    ncat = len(cat)
    nrefcat = len(refcat)

    catdir = os.path.join(sga_dir(), 'ssl')#, ssl_version)

    refoutfile = os.path.join(catdir, f'ssl-parent-refcat-{ssl_version}.fits')
    if os.path.isfile(refoutfile):
        print(f'Warning: existing reference catalog {refoutfile} must be removed by-hand.')
        return
    outfile = os.path.join(catdir, f'ssl-parent-cat-{ssl_version}.fits')
    if os.path.isfile(outfile):
        print(f'Warning: existing catalog {outfile} must be removed by-hand.')
        return

    refcat.write(refoutfile, overwrite=True)
    print(f'Wrote {len(refcat):,d} objects to {refoutfile}')

    cat.write(outfile, overwrite=True)
    print(f'Wrote {len(cat):,d} objects to {outfile}')

    # Ensure each output file has no more than ncatmax objects, to we
    # don't run into memory problems at NERSC.
    nchunk = int(np.ceil(ncat / ncatmax))
    chunkindx = np.array_split(np.arange(ncat), nchunk)
    print(f'Dividing into {nchunk:,d} chunks.')

    for ichunk in range(nchunk):
        h5dir = os.path.join(outdir, ssl_version, 'input')
        if not os.path.isdir(h5dir):
            os.makedirs(h5dir, exist_ok=True)

        h5file = os.path.join(h5dir, f'ssl-parent-chunk{ichunk:03}-{ssl_version}.hdf5')
        if os.path.isfile(h5file) and not overwrite:
            print(f'Skipping existing HDF5 file {h5file}')
            continue

        refs = np.hstack((np.ones(nrefcat, bool), np.zeros(len(chunkindx[ichunk]), bool)))
        rows = np.hstack((refcat['ROW_PARENT'].value, cat['ROW_PARENT'][chunkindx[ichunk]].value))
        ras = np.hstack((refcat['RA'].value, cat['RA'][chunkindx[ichunk]].value))
        decs = np.hstack((refcat['DEC'].value, cat['DEC'][chunkindx[ichunk]].value))
        fitsfiles = np.hstack((refcatfiles, catfiles[chunkindx[ichunk]]))
    
        F = h5py.File(h5file, 'w')
        F.create_dataset('ref', data=refs)
        F.create_dataset('row', data=rows)
        F.create_dataset('ra', data=ras)
        F.create_dataset('dec', data=decs)
    
        images = F.create_dataset('images', (refs.size, nband, width, width))
        for iobj, fitsfile in enumerate(fitsfiles):
            raise ValueError('need to deal with missing bandpasses...and handle i-band')
            img = fitsio.read(fitsfile)
            images[iobj, :] = img
    
        F.close()
        print(f'Wrote {h5file} with {nrefcat:,d} reference objects and ' + \
              f'{len(chunkindx[ichunk]):,d} objects to classify.')


def annotated_montage(cat, outdir='.', region='dr9-north', npagemax=100,
                      ssl_version=None, rescale=False, ssl=False, wisesize=False,
                      lvd=False, zooniverse=False, overwrite=False):
    """Build a single PDF file of annotated images, to enable fast
    visual inspection.

    """
    from glob import glob
    import matplotlib.pyplot as plt
    from matplotlib.patches import Circle
    from matplotlib.backends.backend_pdf import PdfPages
    from matplotlib.image import imread

    if ssl and ssl_version is None:
        print('ssl_version must be specified')
        return

    if ssl:
        qadir = os.path.join(sga_dir(), 'ssl', ssl_version)
    else:
        qadir = os.path.join(sga_dir(), 'parent', 'qa')
    if not os.path.isdir(qadir):
        os.makedirs(qadir, exist_ok=True)

    raslices = get_raslice(cat['RA'].value)
    objnames = radec_to_name(cat['RA'].value, cat['DEC'].value, unixsafe=True)
    if rescale:
        ext = '.jpeg'
        prefix = 'rescale'
        pngdir = os.path.join(outdir, region, 'rescale')
    else:
        ext = '.png'
        prefix = 'annotated'
        pngdir = os.path.join(outdir, region, 'annotate')

    I, pngfiles = [], []
    for ii, (raslice, objname) in enumerate(zip(raslices, objnames)):
        pngfile = os.path.join(pngdir, raslice, f'{objname}{ext}')
        if os.path.isfile(pngfile):
            pngfiles.append(pngfile)
            I.append(ii)
        else:
            print(f'Skipping missing file {pngfile}')
    pngfiles = np.array(pngfiles)
    I = np.array(I)
    cat = cat[I]

    if len(pngfiles) == 0:
        print(f'No color image files found in image directory {pngdir}')
        return
    #pngfiles = np.unique(pngfiles)

    if wisesize:
        suffix = '-wisesize'
    elif lvd:
        suffix = '-lvd'
    elif zooniverse:
        suffix = '-zooniverse'
    elif ssl:
        suffix = f'-ssl-{ssl_version}'
    else:
        suffix = ''

    #pngfiles = np.array(glob(os.path.join(outdir, region, 'annotate', '???', '*.png')))
    #pngfiles = pngfiles[np.argsort(pngfiles)]
    #pngfiles = pngfiles[:16]
    origindx = np.arange(len(pngfiles))
    nobj = len(origindx)

    if nobj <= 10:
        ncol, nrow = 1, 1
    elif (nobj > 10) * (nobj <= 50):
        ncol, nrow = 4, 4
    elif (nobj > 50) * (nobj >= 200):
        ncol, nrow = 6, 6
    else:
        ncol, nrow = 10, 10

    nperpage = ncol * nrow
    npage = int(np.ceil(len(pngfiles) / nperpage))

    # divide into multiple documents
    npdf = int(np.ceil(npage / npagemax))
    pdf_pngfiles = np.array_split(pngfiles, npdf)
    pdf_allindx = np.array_split(origindx, npdf)

    print(f'Distributing {len(pngfiles):,d} annotated images to {npdf:,d} ' + \
          f'PDFs with a total of {npage:,d} pages and {npagemax} pages per file.')

    #for ipdf in [1]:
    for ipdf in range(npdf):
        pdffile = os.path.join(qadir, f'{prefix}-montage-{region}{suffix}-{ipdf:03}.pdf')

        if os.path.isfile(pdffile) and not overwrite:
            print(f'Output file {pdffile} exists; use --overwrite')
            continue

        pngfiles = pdf_pngfiles[ipdf]
        orig_allindx = pdf_allindx[ipdf]
        allindx = np.arange(len(pngfiles))
        npage = int(np.ceil(len(pngfiles) / nperpage))        
    
        pdf = PdfPages(pdffile)
        for ipage in range(npage):
            print(f'Building page {ipage+1:,d}/{npage:,d}')
            indx = allindx[ipage*nperpage:(ipage+1)*nperpage]
            origindx = orig_allindx[ipage*nperpage:(ipage+1)*nperpage]
            fig, ax = plt.subplots(nrow, ncol, figsize=(2*ncol, 2*nrow))
            for iax, xx in enumerate(np.atleast_1d(ax).flat):
                if iax < len(indx):
                    img = imread(pngfiles[indx[iax]])
                    xx.imshow(img, interpolation='None')
                    if rescale:
                        for spine in ['bottom', 'top', 'right', 'left']:
                            xx.spines[spine].set_color('white')
                        xx.set_xticks([])
                        xx.set_yticks([])
                        xx.text(0.9, 0.1, str(cat['ROW_PARENT'][origindx[iax]]), transform=xx.transAxes,
                                ha='right', va='center', color='white', fontsize=8)
                        xx.text(0.05, 0.9, str(cat['OBJNAME'][origindx[iax]]), transform=xx.transAxes,
                                ha='left', va='center', color='white', fontsize=6)
                        sz = img.shape
                        xx.add_artist(Circle((sz[1]/2., sz[0]/2.), radius=15./2/0.262, 
                                             facecolor='none', edgecolor='yellow', ls='-', alpha=0.8))
                    else:
                        xx.axis('off')
                else:
                    xx.axis('off')
            fig.subplots_adjust(wspace=0., hspace=0., bottom=0.05, top=0.95, left=0.05, right=0.95)
            pdf.savefig(fig, dpi=150)
            plt.close()
        pdf.close()
        print(f'Wrote {pdffile}')

        if ssl and False:
            print(pdffile)
            for ipage in range(npage):
                origindx = orig_allindx[ipage*nperpage:(ipage+1)*nperpage]
                info = cat['OBJNAME', 'RA', 'DEC', 'ROW_PARENT'][origindx]
                info['PAGE'] = ipage
                _ = print(info.pprint(max_lines=-1))
            print()

        #pdb.set_trace()


def read_catalog(catalog='sga20205-parent', region='dr9-north', outdir='.',
                 read_fullcat=False, ssl_version=None, ntest=None, annotate=False,
                 ssl=False, wisesize=False, lvd=False, zooniverse=False):
    """Simple wrapper to read a specified catalog.

    """
    from SGA.io import read_fits_catalog

    if catalog == 'sga2025-parent':
        from SGA.io import parent_version
        version = parent_version(archive=True)

        columns = ['OBJNAME', 'FILTERS', 'RA', 'DEC', 'OBJTYPE', 'MORPH', 'Z', 'PGC', 'DIAM_LIT_REF',
                   'DIAM_LIT', 'BA_LIT', 'PA_LIT', 'DIAM_HYPERLEDA', 'BA_HYPERLEDA', 'PA_HYPERLEDA',
                   'DIAM_SGA2020', 'BA_SGA2020', 'PA_SGA2020', 'ROW_LVD', 'ROW_NEDLVS', 'ROW_PARENT',
                   'STARFDIST', 'STARMAG', 'RESOLVED']

        if 'NERSC_HOST' in os.environ:
            catdir = '/global/cfs/cdirs/desicollab/users/ioannis/SGA/2025/parent'
        else:
            catdir = '/Users/ioannis/research/projects/SGA/2025/parent'
                
        catfile = os.path.join(catdir, f'SGA2025-parent-archive-{region}-{version}.fits')

        F = fitsio.FITS(catfile)
        N = F[1].get_nrows()

        # read a test sample
        if ntest is not None:
            rng = np.random.default_rng(seed=1)
            rows = rng.choice(N, size=ntest, replace=False)
            rows = rows[np.argsort(rows)]
        else:
            rows = np.arange(N)

        cat = read_fits_catalog(catfile, columns=columns, rows=rows)

        ###################################################
        #print('HACK!!')
        #from SGA.io import read_lvd
        #from SGA.ellipse import get_basic_geometry
        #from SGA.util import match
        #
        #lvd = read_lvd()
        #cat = get_basic_geometry(lvd)
        #cat.rename_column('GALAXY', 'OBJNAME')
        #cat['RA'] = lvd['RA']
        #cat['DEC'] = lvd['DEC']
        #cat['ROW_LVD'] = lvd['ROW']
        #cat['ROW_PARENT'] = lvd['ROW']
        #cat['OBJTYPE'] = 'G                '
        #cat['MORPH'] = '                             '
        #cat['DIAM_SGA2020'] = -99.
        #cat['DIAM_HYPERLEDA'] = -99.
        #cat['BA_SGA2020'] = -99.
        #cat['BA_HYPERLEDA'] = -99.
        #cat['PA_SGA2020'] = -99.
        #cat['PA_HYPERLEDA'] = -99.
        #
        #catfile = '/global/cfs/cdirs/desicollab/users/ioannis/SGA/2025/parent/SGA2025-parent-archive-v1.0.fits'
        #allrows = fitsio.read(catfile, columns='ROW_LVD')
        #I = np.where(np.isin(allrows, lvd['ROW'].value))[0]
        #lvdcat = Table(fitsio.read(catfile, rows=I))
        #indx_cat, indx_lvdcat = match(cat['OBJNAME'], lvdcat['OBJNAME'])
        #
        #cat['OBJTYPE'][indx_cat] = lvdcat['OBJTYPE'][indx_lvdcat]
        #cat['MORPH'][indx_cat] = lvdcat['MORPH'][indx_lvdcat]
        #cat['DIAM_SGA2020'][indx_cat] = lvdcat['DIAM_SGA2020'][indx_lvdcat]
        #cat['DIAM_HYPERLEDA'][indx_cat] = lvdcat['DIAM_HYPERLEDA'][indx_lvdcat]
        #cat['BA_SGA2020'][indx_cat] = lvdcat['BA_SGA2020'][indx_lvdcat]
        #cat['BA_HYPERLEDA'][indx_cat] = lvdcat['BA_HYPERLEDA'][indx_lvdcat]
        #cat['PA_SGA2020'][indx_cat] = lvdcat['PA_SGA2020'][indx_lvdcat]
        #cat['PA_HYPERLEDA'][indx_cat] = lvdcat['PA_HYPERLEDA'][indx_lvdcat]
        ###################################################

        if ssl and ssl_version is None:
            print('ssl_version must be specified')
            return

        # when annotating, must make a copy *before* any cuts!
        if read_fullcat or annotate or ssl or lvd:
            if ntest is not None:
                fullcat = read_fits_catalog(catfile, columns=columns, rows=None)
            else:
                fullcat = cat.copy()
        else:
            fullcat = None

        def writeit(cat, region, prefix='tmplist'):
            outfile = f'{prefix}-{region}.txt'
            out = cat['OBJNAME', ]
            #out['COMMENT'] = 'drop,faint shred or compact'
            out.write(outfile, format='ascii.csv', overwrite=True)
            print(f'Wrote {outfile}')

        #if False:
        #    diam, _, _, _ = choose_geometry(cat, mindiam=0.)
        #    #cat = cat[np.isin(cat['OBJNAME'], ['CGCG 480-040', 'MCG -01-06-008', 'ESO 297- G 033'])]
        #    pdb.set_trace()            

        if False:#True:
            # All objects with diameter<30 arcsec and no other source
            # within 30 arcsec.
            from SGA.util import find_close
            fullcat = cat.copy()
            
            primaries, groups = find_close(cat, cat, rad_arcsec=45., isolated=True)
            diam, _, _, _ = choose_geometry(primaries, mindiam=0.)
            cat = primaries[diam < 30.]#[:128]
            #writeit(cat, region)


        if False:#True:
            from SGA.ellipse import ellipse_mask_sky

            #########################
            # All sources larger than XX arcmin with at least one
            # other object within its diameter.
            fullcat = cat.copy()
            fullcat_diam, fullcat_ba, fullcat_pa, _ = choose_geometry(fullcat, mindiam=0.)

            isolated = True
            if isolated:
                #I = (fullcat_diam <= 20.) * (fullcat['ROW_LVD'] == -99) * ~fullcat['RESOLVED']
                #I = (fullcat_diam/60. > 1.) * ~fullcat['RESOLVED']
                I = (fullcat_diam > 50.) * (fullcat_diam <= 60.) * ~fullcat['RESOLVED']
            else:
                #I = (fullcat_diam/60. > 4.) * (fullcat_diam/60. < 50.) * ~fullcat['RESOLVED']
                #I = (fullcat_diam/60. > 2.) * (fullcat_diam/60. < 4.) * ~fullcat['RESOLVED']
                #I = (fullcat_diam/60. > 1.) * (fullcat_diam/60. < 2.) * ~fullcat['RESOLVED']
                I = (fullcat_diam > 30.) * (fullcat_diam <= 60.) * ~fullcat['RESOLVED']
                #I = (fullcat_diam/60. > 1.) * ~fullcat['RESOLVED']
                #print('HACK!!')
                #I = np.isin(cat['OBJNAME'], ['NGC 5349'])#['NGC 0019'])#, 'ESO 241- G 020'])

            print(np.sum(I))
            cat = cat[I]
            diam = fullcat_diam[I]
            ba = fullcat_ba[I]
            pa = fullcat_pa[I]

            allmatches = match_radec(cat['RA'].value, cat['DEC'].value,
                                     fullcat['RA'].value, fullcat['DEC'].value,
                                     np.max(diam)/3600., indexlist=True, 
                                     notself=False, count=True)
            outcat, outfullcat = [], []

            if isolated:
                prefix = 'isolated'
            else:
                prefix = 'tmplist'

            for iobj in range(len(cat)):
                if isolated:
                    # refine the search to this object's diameter
                    _, m2, _ = match_radec(cat['RA'][iobj], cat['DEC'][iobj],
                                           fullcat['RA'][allmatches[iobj]],
                                           fullcat['DEC'][allmatches[iobj]],
                                           0.75*diam[iobj]/3600.)
                    # isolated!
                    if len(m2) == 1:
                        outcat.append(cat[[iobj]])
                        outfullcat.append(fullcat[allmatches[iobj]][m2])
                else:
                    if len(allmatches[iobj]) == 1:
                        m2 = [0]
                        prefix_this = ''
                        diam_this = [-99.]
                    else:
                        # find neighbors within this object's elliptical aperture
                        ras, decs = fullcat['RA'][allmatches[iobj]], fullcat['DEC'][allmatches[iobj]]
                        racen, deccen = cat['RA'][iobj], cat['DEC'][iobj]
        
                        semia = diam[iobj] / 2. / 3600. # [degrees]
                        semib = ba[iobj] * semia
                        phi = np.radians(90. - pa[iobj])
        
                        m2 = np.where(ellipse_mask_sky(racen, deccen, semia, semib, phi, ras, decs))[0]

                        # hack!
                        prefix_this = np.array(list(zip(*np.char.split(fullcat['OBJNAME'][allmatches[iobj]][m2].value, ' ').tolist()))[0])
                        diam_this = fullcat_diam[allmatches[iobj]][m2]

                    # at least one other object
                    if len(m2) > 1 and np.any(diam_this == 0.):
                    #if len(m2) > 1 and 'WISEA' in prefix_this and np.any(diam_this == 0.):
                        outcat.append(cat[[iobj]])
                        outfullcat.append(fullcat[allmatches[iobj]][m2])

            cat = vstack(outcat)
            print(len(cat))
            #allprefix = np.array(list(zip(*np.char.split(cat['OBJNAME'].value, ' ').tolist()))[0])

            cat = cat[:100]

            _cat = vstack(outfullcat)
            _, uindx = np.unique(_cat['OBJNAME'], return_index=True)
            _cat = _cat[uindx]

            #print('HACK - removing central galaxy from tmplist!')
            #_cat = _cat[~np.isin(_cat['OBJNAME'], cat['OBJNAME'])]

            _cat = _cat[np.argsort(_cat['RA'])]
            writeit(_cat, region, prefix=prefix)
            pdb.set_trace()

            ##########################
            ## All objects with at least one other sources within XX arcsec.
            #from SGA.util import resolve_close
            #
            #fullcat = cat.copy()
            #rad_arcsec = 5.#10.#1.5
            #
            #cat = find_close(cat, fullcat, rad_arcsec=rad_arcsec)
            #pdb.set_trace()
            #fullcat = resolve_close(cat, fullcat, maxsep=rad_arcsec, allow_vetos=False, trim=True, verbose=False)#True)
            #
            #cat = find_close(cat, fullcat, rad_arcsec=rad_arcsec)

            ##########################
            ## All objects with diameter==0 and no other source within
            ## 30 arcsec.
            #from SGA.util import find_close
            #fullcat = cat.copy()
            #
            #primaries, groups = find_close(cat, cat, rad_arcsec=30., isolated=True)
            #diam, _, _, _ = choose_geometry(primaries, mindiam=0.)
            #cat = primaries[diam == 0.]#[:128]
            #write_junk(cat, region)

            #########################
            ## All objects larger than XX arcmin that have an SDSS source near them.
            #fullcat = cat.copy()
            #I = (diam > 5.*60.)
            #cat = cat[I]
            #
            #allmatches = match_radec(cat['RA'].value, cat['DEC'].value,
            #                         fullcat['RA'].value, fullcat['DEC'].value,
            #                         1./60., indexlist=True, notself=False)
            #refindx = []
            #for ii, mm in enumerate(allmatches):
            #    if len(mm) > 1:
            #        if np.any('SDSS' in ' '.join(fullcat['OBJNAME'][mm].value)):
            #            refindx.append(ii)
            #refindx = np.array(refindx)
            #cat = fullcat[I][refindx]


        if False:#True:
            I = (cat['DIAM_LIT'] < 0.) * (np.char.find(cat['OBJNAME'].value, 'LSBG') != -1)
            cat = cat[I]

        if True:
            # one-by-one checks
            #cat = cat[np.isin(cat['OBJNAME'], ['WISEA J110416.71-003141.3'])]
            #cat = cat[np.isin(cat['OBJNAME'], ['MCG +00-11-011'])]
            #cat = cat[np.isin(cat['OBJNAME'], ['WISEA J023242.56+005813.7'])]
            #cat = cat[np.isin(cat['OBJNAME'], ['MCG -02-28-007'])]
            cat = cat[np.isin(cat['OBJNAME'], ['ESO 569- G 005'])]
            #cat = cat[np.isin(cat['OBJNAME'], ['ESO 054- G 004'])]
            #cat = cat[np.isin(cat['OBJNAME'], ['ESO 002- G 013', 'WISEA J110416.71-003141.3'])]
            #cat = cat[np.isin(cat['OBJNAME'], ['UGC 00579', 'IC 1860'])]
            #cat = cat[cat['OBJNAME'] == 'UGC 03214']
            #m1, m2, _ = match_radec(cat['RA'], cat['DEC'], 27.2007, 10.5151, 120./3600.)
            #cat = cat[m1]
            #print(cat['OBJNAME', 'ROW_PARENT'])
            #pdb.set_trace()
            #diam, ba, pa, ref = choose_geometry(cat)
            #parse_geometry(cat, 'SMUDGes')

        if False:
            # SMUDGes
            prefix = np.array(list(zip(*np.char.split(cat['OBJNAME'].value, ' ').tolist()))[0])
            cat = cat[(prefix == 'SMDG') * (cat['DIAM_LIT'] > 0.)]#[:8]
            diam, ba, pa, ref = choose_geometry(cat)
            #pdb.set_trace()

        # Kim's wisesize project
        if wisesize:
            # 87. < RA < 300.
            # -10. < DEC < 85.
            # 0.002 < z < 0.025
            # W3 or NUV SNR > 20.   (for this, I divided  'Lum_W3'/'Lum_W3_unc' and 'Lum_NUV'/'Lum_NUV_unc', respectively)
            # diameter > 15. arcsec OR -99., as we are including objects which do not have size measurements in your nedgeometry catalog
            # Lastly, we removed VFS galaxies, since we already have access to those postage stamps
            from SGA.io import read_nedlvs
            from SGA.util import match

            def get_snr(flux, ferr):
                snr = np.zeros(len(flux))
                J = np.isfinite(flux) * np.isfinite(ferr) * (ferr > 0.)
                snr[J] = flux[J] / ferr[J]
                return snr

            nedlvs = read_nedlvs()

            I = cat['FILTERS'] == 'grz'
            print(f'In {region} grz footprint: {np.sum(I):,d}')
            cat = cat[I]
            nobj = len(cat)

            cat = cat[cat['ROW_NEDLVS'] != -99]
            indx_cat, indx_nedlvs = match(cat['ROW_NEDLVS'], nedlvs['ROW'])
            cat = cat[indx_cat]
            nedlvs = nedlvs[indx_nedlvs]
            print(f'In NED-LVS: {len(cat):,d}/{nobj:,d}')

            I = (cat['RA'] > 87.) * (cat['RA'] < 300.) * (cat['DEC'] > -10.) * (cat['DEC'] < 85.)
            print(f'In 87<RA<300, -10<Dec<85: {np.sum(I):,d}/{len(cat):,d}')
            cat = cat[I]
            nedlvs = nedlvs[I]

            I = (nedlvs['Z'] > 0.002) * (nedlvs['Z'] < 0.025)
            print(f'In 0.002<z<0.025 range: {np.sum(I):,d}/{len(cat):,d}')
            cat = cat[I]
            nedlvs = nedlvs[I]

            mindiam = 30. # [arcsec] # 15.
            diam, _, _, _ = choose_geometry(cat, mindiam=0.)

            I = (diam > mindiam)
            print(f'Diameter (>{mindiam:.0f} arcsec) cut: {np.sum(I):,d}/{len(cat):,d}')
            cat = cat[I]
            nedlvs = nedlvs[I]

            snrmin = 3. # 20.
            snr_W3 = get_snr(nedlvs['LUM_W3'], nedlvs['LUM_W3_UNC'])
            snr_NUV = get_snr(nedlvs['LUM_NUV'], nedlvs['LUM_NUV_UNC'])

            I = np.logical_or(snr_W3 > snrmin, snr_NUV > snrmin)
            print(f'S/N(W3)>{snrmin:.0f}, S/N(NUV)>{snrmin:.0f} cuts: {np.sum(I):,d}/{len(cat):,d}')
            cat = cat[I]
            nedlvs = nedlvs[I]

            #print('Hack!')
            #cat = cat[:10]

            #vfs = Table(fitsio.read('/global/homes/i/ioannis/ioannis/legacyhalos/virgofilaments/vf_north_v2_main.fits'))
            #m1, m2, _ = match_radec(cat['RA'], cat['DEC'], vfs['RA'], vfs['DEC'], 3./3600.)
            #I = np.delete(np.arange(len(cat)), m1)
            #cat = cat[I]
            #nedlvs = nedlvs[I]
            #diam, _, _, _ = choose_geometry(cat, mindiam=0.)

            if not os.path.isdir(outdir):
                os.makedirs(outdir, exist_ok=True)
            outfile = os.path.join(outdir, f'wiseize-parent-{region}.fits')

            if not os.path.isfile(outfile):
                rows = np.where(np.isin(fitsio.read(catfile, columns='ROW_PARENT'), cat['ROW_PARENT'].value))[0]
                allcat = read_fits_catalog(catfile, rows=rows)
                indx_cat, indx_allcat = match(cat['ROW_PARENT'], allcat['ROW_PARENT'])
    
                allcat = allcat[indx_allcat]
                cat = cat[indx_cat]
                nedlvs = nedlvs[indx_cat]
    
                assert(np.all(allcat['ROW_PARENT'] == cat['ROW_PARENT']))
                allcat.write(outfile, overwrite=True)
                print(f'Wrote {len(allcat):,d} objects to {outfile}')
    
                outfile = os.path.join(outdir, f'wiseize-nedlvs-{region}.fits')
                nedlvs.write(outfile, overwrite=True)
                print(f'Wrote {len(nedlvs):,d} objects to {outfile}')


        if lvd:
            # analyze the LVD sample
            #diam, _, _, _ = choose_geometry(cat, mindiam=0.)
            #cat = cat[(cat['ROW_LVD'] != -99) * (diam == 0.)] # (diam > 20.*60.)]
            cat = cat[cat['ROW_LVD'] != -99]
            cat = cat[~np.isin(cat['OBJNAME'], ['LMC', 'Sagittarius', 'SMC'])]

            fulldiam, _, _, _ = choose_geometry(fullcat, mindiam=0.)
            fullcat = fullcat[fulldiam > 30./60.]

        if zooniverse:
            # project0
            ## analyze the Zooniverse sample; toss out by STARFDIST?
            #diam, _, _, _ = choose_geometry(cat, mindiam=0.)
            #I = (diam > 3.*60.) * ~cat['RESOLVED']# * (cat['FILTERS'] == 'grz')
            #cat = cat[I]
            #if annotate:
            #    diam, _, _, _ = choose_geometry(fullcat, mindiam=0.)
            #    I = diam > 15.
            #    print(f'Trimmed fullcat to {np.sum(I):,d}/{len(fullcat):,d} objects with diam>15 arcsec')
            #    fullcat = fullcat[I]

            # project1
            from SGA.io import read_zooniverse_sample
            project = 'project1'
            cat, fullcat = read_zooniverse_sample(cat, fullcat=fullcat, catfile=catfile, 
                                                  region=region, outdir=outdir, project=project)

        if ssl:
            # read Sara's ssl-legacysurvey file
            from glob import glob

            catdir = os.path.join(sga_dir(), 'ssl')#, ssl_version)
            cat = Table(fitsio.read(os.path.join(catdir, f'ssl-parent-cat-{ssl_version}.fits')))
            refcat = Table(fitsio.read(os.path.join(catdir, f'ssl-parent-refcat-{ssl_version}.fits')))

            cat = cat[cat['REGION'] == region]
            refcat = refcat[refcat['REGION'] == region]

            sslfiles = glob(os.path.join(outdir, ssl_version, 'output', '*.txt'))
            allssl = vstack([Table.read(sslfile, format='ascii.commented_header') for sslfile in sslfiles])
            _, I = np.unique(allssl['ROW'], return_index=True)
            allssl = allssl[I]

            ssl_cat = allssl[np.isin(allssl['ROW'], cat['ROW_PARENT'])]
            ssl_refcat = allssl[np.isin(allssl['ROW'], refcat['ROW_PARENT'])]

            if False:#True:
                # first investigate refcat
                cat = refcat[np.isin(refcat['ROW_PARENT'], ssl_refcat['ROW'])]
            else:
                # investigate cat
                cat = cat[np.isin(cat['ROW_PARENT'], ssl_cat['ROW'])]
                #print(cat.pprint(max_lines=-1))
                pdb.set_trace()

            ## test code to identify objects with no other sources within 30 arcsec
            #fullcat = read_fits_catalog(catfile, columns=columns, rows=None)
            #matches = match_radec(cat['RA'].value, cat['DEC'].value, fullcat['RA'].value,
            #                      fullcat['DEC'].value, 30./3600., indexlist=True, notself=True)
            #indx_isolated = []
            #for iobj, onematch in enumerate(matches):
            #    if onematch is None:
            #        continue
            #    if len(onematch) == 1:
            #        indx_isolated.append(iobj)
            #indx_isolated = np.array(indx_isolated)
            #cat = cat[indx_isolated]

            #cat = cat[0:490] # 1000:1110]


        # more testing below here
        if False:
            #try:
            #    from importlib import resources
            #    vetofile = os.path.join(resources.files('SGA').joinpath('data/SGA2025'), 'ssl-veto-v1.txt')
            #except:
            #    from pkg_resources import resource_filename
            #    vetofile = resource_filename('SGA', 'data/SGA2025/ssl-veto-v1.txt')
            vetofile = '/global/u2/i/ioannis/code/git/SGA/py/SGA/data/SGA2025/ssl-veto-v1.txt'
            veto = Table.read(vetofile, format='csv', comment='#')
            veto = veto[veto['comment'] == region]

            cat = cat[np.isin(cat['OBJNAME'], veto['objname'])]
            #veto[~np.isin(veto['objname'], cat['OBJNAME'])]

            ## SGA-2020 missing objects
            #miss = Table(fitsio.read(os.path.join(sga_dir(), 'sandbox', 'sga2020-missing.fits')))
            #m1, m2, _ = match_radec(cat['RA'], cat['DEC'], miss['RA'], miss['DEC'], 5./3600., nearest=True)
            ##m1, m2, _ = match_radec(cat['RA'], cat['DEC'], miss['RA'], miss['DEC'], 60./3600.)
            ##m1 = np.unique(m1)
            #cat = cat[m1]
            #cat = cat[np.argsort(cat['RA'])]
            ##cat = cat[cat['OBJNAME'] == 'WISEA J163631.04+461928.3']
            ##diam, ba, pa, ref = choose_geometry(cat)

        print(f'Trimmed to {len(cat):,d} objects.')


    sort_by_ra = True#False
    sort_by_diameter = False#True
    if sort_by_ra:
        print('Sorting by RA')
        cat = cat[np.argsort(cat['RA'])]
    elif sort_by_diameter:
        print('Sorting by diameter')
        diam, _, _, _ = choose_geometry(cat, mindiam=0.)
        cat = cat[np.argsort(diam)[::-1]]
    else:
        print('Sorting by OBJNAME')
        cat = cat[np.argsort(cat['OBJNAME'])]

    if len(cat) == 0:
        raise ValueError('No objects in catalog!')

    return cat, fullcat


def main():
    """Main wrapper.

    """
    import argparse    
    
    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument('--catalog', type=str, default='sga2025-parent', choices=['sga2025-parent'], help='Catalog to read.')
    parser.add_argument('--region', default='dr9-north', choices=['dr9-north', 'dr9-south', 'dr10-south', 'dr11-south'], 
                        type=str, help='Region to analyze (only for --catalog="sga2025-parent").')
    parser.add_argument('--mp', type=int, default=1, help='Number of multiprocessing processes per MPI rank or node.')
    parser.add_argument('--ntest', type=int, default=None, help='Number of test objects to read.')
    parser.add_argument('--width', type=int, default=152, help='Default cutout width [pixels].')
    parser.add_argument('--pixscale', type=float, default=0.262, help='Default pixel scale [arcsec/pixel].')
    parser.add_argument('--outdir', default='./', type=str, help='Base output data directory.')
    parser.add_argument('--httpdir', default=None, type=str, help='Base https output data directory.')

    parser.add_argument('--ssl', action='store_true', help='Analyze the ssl-legacysurvey samples.')
    parser.add_argument('--build-ssl', action='store_true', help='Build the hdf5 files needed by ssl-legacysurvey.')
    parser.add_argument('--ssl-version', default=None, type=str, help='Version number.')

    parser.add_argument('--lvd', action='store_true', help='Analyze the LVD sample.')
    parser.add_argument('--zooniverse', action='store_true', help='Analyze the zooniverse sample.')
    parser.add_argument('--wisesize', action='store_true', help='Analyze the wisesize sample.')

    parser.add_argument('--plan', action='store_true', help='Plan how many nodes to use and how to distribute the targets.')
    parser.add_argument('--photo', action='store_true', help='Perform photometry.')
    parser.add_argument('--annotate', action='store_true', help='Annotate the native-resolution cutouts.')
    parser.add_argument('--annotate-central-only', action='store_true', help='Only annotate the central galaxy.')
    parser.add_argument('--annotated-montage', action='store_true', help='Generate multipage montages of annotated images.')
    parser.add_argument('--no-fits-cutouts', action='store_false', dest='fits_cutouts', help='Do not generate FITS cutouts.')
    parser.add_argument('--ivar-cutouts', action='store_true', help='Generate ivar cutouts.')
    parser.add_argument('--dry-run', action='store_true', help='Generate but do not run commands.')
    parser.add_argument('--rescale', action='store_true', help='Scale the pixel size.')
    parser.add_argument('--debug', action='store_true', help='Print out a variety of debugging messages.')
    parser.add_argument('--verbose', action='store_true', help='Be verbose.')
    parser.add_argument('--overwrite', action='store_true', help='Overwrite any existing output files.')

    args = parser.parse_args()

    try:
        from mpi4py import MPI
        comm = MPI.COMM_WORLD
    except ImportError:
        comm = None

    # https://docs.nersc.gov/development/languages/python/parallel-python/#use-the-spawn-start-method
    if args.mp > 1 and 'NERSC_HOST' in os.environ:
        import multiprocessing
        multiprocessing.set_start_method('spawn')

    if comm is None:
        rank, size = 0, 1
    else:
        rank, size = comm.rank, comm.size

    # define paths depending on the input keywords
    if args.build_ssl:
        #cutoutdir = os.path.join(args.outdir, args.region, 'rescale')
        pass
    else:
        # annotated cutouts
        if args.photo:
            layer = None
            indir = os.path.join(args.outdir, args.region, 'native')
            outdir = indir
        elif args.annotate:
            layer = None
            indir = os.path.join(args.outdir, args.region, 'native')
            outdir = os.path.join(args.outdir, args.region, 'annotate')
        else:
            # native or rescaled cutouts
            indir = None
            layer = f'ls-{args.region}'
            if args.region == 'dr11-south':
                print(f"WARNING: Overriding layer={layer}-->ls-dr11-early")
                layer = 'ls-dr11-early'
            if args.rescale:
                outdir = os.path.join(args.outdir, args.region, 'rescale')
            else:
                outdir = os.path.join(args.outdir, args.region, 'native')


    cat, fullcat = None, None
    if rank == 0:
        if args.build_ssl:
            if args.ssl_version is None:
                raise ValueError('ssl_version must be specified')
            if args.ssl_version == 'v1' or args.ssl_version == 'v2':
                cat_north, fullcat_north = read_catalog(args.catalog, read_fullcat=True, region='dr9-north')
                cat_south, fullcat_south = read_catalog(args.catalog, read_fullcat=True, region='dr9-south')
                cat_north['REGION'] = 'dr9-north'
                cat_south['REGION'] = 'dr9-south'
                fullcat_north['REGION'] = 'dr9-north'
                fullcat_south['REGION'] = 'dr9-south'
            elif args.ssl_version == 'v3' or args.ssl_version == 'v4':
                cat_north, fullcat_north = read_catalog(args.catalog, read_fullcat=True, region='dr9-north')
                cat_south, fullcat_south = read_catalog(args.catalog, read_fullcat=True, region='dr11-south')
                cat_north['REGION'] = 'dr9-north'
                cat_south['REGION'] = 'dr11-south'
                fullcat_north['REGION'] = 'dr9-north'
                fullcat_south['REGION'] = 'dr11-south'
            else:
                raise ValueError(f'Unsupported ssl_version {args.ssl_version}')
            cat = vstack((cat_north, cat_south))
            fullcat = vstack((fullcat_north, fullcat_south))
            del cat_north, cat_south, fullcat_north, fullcat_south
        else:
            cat, fullcat = read_catalog(args.catalog, region=args.region, annotate=args.annotate, 
                                        outdir=args.outdir, ntest=args.ntest, wisesize=args.wisesize, 
                                        lvd=args.lvd, zooniverse=args.zooniverse, ssl=args.ssl,
                                        ssl_version=args.ssl_version)

    if comm is not None:
        cat = comm.bcast(cat, root=0)
        fullcat = comm.bcast(fullcat, root=0)

    if args.annotated_montage and rank == 0:
        annotated_montage(cat, region=args.region, outdir=args.outdir, ssl=args.ssl,
                          ssl_version=args.ssl_version, rescale=args.rescale, 
                          wisesize=args.wisesize, lvd=args.lvd,
                          zooniverse=args.zooniverse, overwrite=args.overwrite)
        return
        
    if args.build_ssl and rank == 0:
        build_ssl_legacysurvey(cat, fullcat, width=args.width, ssl_version=args.ssl_version,
                               outdir=args.outdir, overwrite=args.overwrite,
                               verbose=args.verbose)
        return

    # no FITS cutouts needed for the Zooniverse project
    fits_cutouts = args.fits_cutouts
    ivar_cutouts = args.ivar_cutouts
    unwise_cutouts = False
    galex_cutouts = False
    draw_largest_ellipse = False

    if args.zooniverse:
        fits_cutouts = False
        draw_largest_ellipse = True
    elif args.wisesize:
        ivar_cutouts = True
        unwise_cutouts = True
        galex_cutouts = False # True
    else:
        pass

    if args.plan and rank == 0:
        if args.photo:
            width = None
        elif args.annotate:
            width = None
        else:
            mindiam = args.width * args.pixscale # [arcsec]
            diam, ba, pa, ref = choose_geometry(cat, mindiam=mindiam)

            pixscale, width = get_pixscale_and_width(
                diam, mindiam, rescale=args.rescale, 
                default_width=args.width, 
                default_pixscale=args.pixscale)

        plan(cat, width=width, layer=layer, size=size, indir=indir,
             outdir=outdir, mp=args.mp, annotate=args.annotate,
             photo=args.photo, fits_cutouts=fits_cutouts,
             unwise_cutouts=unwise_cutouts, galex_cutouts=galex_cutouts,
             overwrite=args.overwrite, verbose=args.verbose)
        return

    if args.photo:
        do_photo(cat, comm=comm, mp=args.mp, indir=indir, region=args.region, 
                 outdir=outdir, overwrite=args.overwrite, 
                 dry_run=args.dry_run, verbose=args.verbose)
    elif args.annotate:
        do_annotate(cat, fullcat, default_pixscale=args.pixscale, 
                    default_width=args.width, mp=args.mp, 
                    comm=comm, indir=indir, base_outdir=args.outdir,
                    region=args.region, httpdir=args.httpdir, outdir=outdir, 
                    overwrite=args.overwrite, fits_cutouts=fits_cutouts,
                    draw_largest_ellipse=draw_largest_ellipse,
                    annotate_central_only=args.annotate_central_only,
                    debug=args.debug, dry_run=args.dry_run, verbose=args.verbose)
    else:
        do_cutouts(cat, layer=layer, mp=args.mp, comm=comm, outdir=outdir, 
                   base_outdir=args.outdir, default_pixscale=args.pixscale, 
                   default_width=args.width, rescale=args.rescale, 
                   overwrite=args.overwrite, dry_run=args.dry_run, 
                   fits_cutouts=fits_cutouts, ivar_cutouts=ivar_cutouts, 
                   unwise_cutouts=unwise_cutouts, galex_cutouts=galex_cutouts,
                   verbose=args.verbose)

if __name__ == '__main__':
    main()
